{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Tuning Example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import libraries\n",
    "import pandas as pd\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "model_name = 'bigscience/bloomz-560m'\n",
    "NUM_VIRTUAL_TOKENS = 10\n",
    "NUM_EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "foundational_model = AutoModelForCausalLM.from_pretrained(model_name,\n",
    "                                                          trust_remote_code = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a function that returns the outputs from the model we have received above, and inputs.\n",
    "def get_outputs(model, inputs, max_new_tokens = 100):\n",
    "    outputs = model.generate(\n",
    "        input_ids = inputs['input_ids'],\n",
    "        attention_mask = inputs['attention_mask'],\n",
    "        max_new_tokens = max_new_tokens,\n",
    "        repetition_penalty = 1.5, \n",
    "        early_stopping = True,\n",
    "        eos_token_id = tokenizer.eos_token_id,\n",
    "        num_beams = 6\n",
    "    )\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"I want you to act as a motivational coach. Don't be afraid to ask questions\"]\n"
     ]
    }
   ],
   "source": [
    "## get a smaple response from the above get_output and existing foundational models\n",
    "test_prompt = 'I want you to act as a motivational coach.'\n",
    "\n",
    "input_prompt = tokenizer(test_prompt, return_tensors = 'pt')\n",
    "foundational_outputs_prompt = get_outputs(foundational_model, input_prompt, max_new_tokens = 50)\n",
    "\n",
    "print(tokenizer.batch_decode(foundational_outputs_prompt, skip_special_tokens = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['There are two things that matter: quality and quantity. quality matters more than quantity.']\n"
     ]
    }
   ],
   "source": [
    "## get a smaple response from the above get_output and existing foundational models\n",
    "test_sentence = 'There are two things that matter:'\n",
    "\n",
    "input_sentences = tokenizer(test_sentence, return_tensors = 'pt')\n",
    "foundational_outputs_sentence = get_outputs(foundational_model, input_sentences, max_new_tokens = 50)\n",
    "\n",
    "print(tokenizer.batch_decode(foundational_outputs_sentence, skip_special_tokens = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask'],\n",
       "    num_rows: 50\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## preparing the datasets\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset_prompt = 'fka/awesome-chatgpt-prompts'\n",
    "\n",
    "#create the dataset to create prompts\n",
    "data_prompt = load_dataset(dataset_prompt)\n",
    "data_prompt = data_prompt.map(lambda samples:tokenizer(samples['prompt']), batched = True)\n",
    "train_sample_prompt = data_prompt['train'].select(range(50))\n",
    "\n",
    "train_sample_prompt = train_sample_prompt.remove_columns(['act','prompt'])\n",
    "\n",
    "display(train_sample_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 267, 104105, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 660, 7165, 24...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 660, 33322, 2...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 267, 49760, 1...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 267, 5484, 11...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 660, 7165, 14...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 267, 93949, 7...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 267, 25008, 2...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 267, 159667, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 3269, 731, 84491, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 660, 32482, 6...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 267, 26143, 8...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 267, 33929, 1...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 267, 8947, 22...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 267, 22675, 3...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 267, 123873, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 267, 180898, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 267, 16860, 6...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 267, 19901, 8...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 267, 22422, 6...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 267, 51651, 2...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 267, 23556, 6...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 267, 57046, 1...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 267, 213382, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 267, 22675, 3...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 267, 97350, 5...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 267, 213939, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 267, 23213, 5...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 660, 75299, 2...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 267, 764, 168...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 267, 102127, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 267, 31192, 8...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 267, 10440, 6...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 267, 173675, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 267, 11051, 1...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 267, 5630, 53...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 267, 59436, 1...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 267, 4620, 26...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 267, 9022, 19...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 267, 22191, 1...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 267, 2910, 10...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 267, 230674, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 267, 48488, 6...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 267, 6848, 94...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 660, 75299, 1...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 267, 27738, 5...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 660, 13538, 4...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>[44, 12865, 20886, 5268, 1400, 12580, 192316, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>[95694, 57624, 1002, 116270, 664, 215903, 3669...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 660, 53292, 2...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            input_ids  \\\n",
       "0   [44, 4026, 1152, 427, 1769, 661, 267, 104105, ...   \n",
       "1   [44, 4026, 1152, 427, 1769, 661, 660, 7165, 24...   \n",
       "2   [44, 4026, 1152, 427, 1769, 661, 660, 33322, 2...   \n",
       "3   [44, 4026, 1152, 427, 1769, 661, 267, 49760, 1...   \n",
       "4   [44, 4026, 1152, 427, 1769, 661, 267, 5484, 11...   \n",
       "5   [44, 4026, 1152, 427, 1769, 661, 660, 7165, 14...   \n",
       "6   [44, 4026, 1152, 427, 1769, 661, 267, 93949, 7...   \n",
       "7   [44, 4026, 1152, 427, 1769, 661, 267, 25008, 2...   \n",
       "8   [44, 4026, 1152, 427, 1769, 661, 267, 159667, ...   \n",
       "9   [44, 4026, 1152, 427, 1769, 3269, 731, 84491, ...   \n",
       "10  [44, 4026, 1152, 427, 1769, 661, 660, 32482, 6...   \n",
       "11  [44, 4026, 1152, 427, 1769, 661, 267, 26143, 8...   \n",
       "12  [44, 4026, 1152, 427, 1769, 661, 267, 33929, 1...   \n",
       "13  [44, 4026, 1152, 427, 1769, 661, 267, 8947, 22...   \n",
       "14  [44, 4026, 1152, 427, 1769, 661, 267, 22675, 3...   \n",
       "15  [44, 4026, 1152, 427, 1769, 661, 267, 123873, ...   \n",
       "16  [44, 4026, 1152, 427, 1769, 661, 267, 180898, ...   \n",
       "17  [44, 4026, 1152, 427, 1769, 661, 267, 16860, 6...   \n",
       "18  [44, 4026, 1152, 427, 1769, 661, 267, 19901, 8...   \n",
       "19  [44, 4026, 1152, 427, 1769, 661, 267, 22422, 6...   \n",
       "20  [44, 4026, 1152, 427, 1769, 661, 267, 51651, 2...   \n",
       "21  [44, 4026, 1152, 427, 1769, 661, 267, 23556, 6...   \n",
       "22  [44, 4026, 1152, 427, 1769, 661, 267, 57046, 1...   \n",
       "23  [44, 4026, 1152, 427, 1769, 661, 267, 213382, ...   \n",
       "24  [44, 4026, 1152, 427, 1769, 661, 267, 22675, 3...   \n",
       "25  [44, 4026, 1152, 427, 1769, 661, 267, 97350, 5...   \n",
       "26  [44, 4026, 1152, 427, 1769, 661, 267, 213939, ...   \n",
       "27  [44, 4026, 1152, 427, 1769, 661, 267, 23213, 5...   \n",
       "28  [44, 4026, 1152, 427, 1769, 661, 660, 75299, 2...   \n",
       "29  [44, 4026, 1152, 427, 1769, 661, 267, 764, 168...   \n",
       "30  [44, 4026, 1152, 427, 1769, 661, 267, 102127, ...   \n",
       "31  [44, 4026, 1152, 427, 1769, 661, 267, 31192, 8...   \n",
       "32  [44, 4026, 1152, 427, 1769, 661, 267, 10440, 6...   \n",
       "33  [44, 4026, 1152, 427, 1769, 661, 267, 173675, ...   \n",
       "34  [44, 4026, 1152, 427, 1769, 661, 267, 11051, 1...   \n",
       "35  [44, 4026, 1152, 427, 1769, 661, 267, 5630, 53...   \n",
       "36  [44, 4026, 1152, 427, 1769, 661, 267, 59436, 1...   \n",
       "37  [44, 4026, 1152, 427, 1769, 661, 267, 4620, 26...   \n",
       "38  [44, 4026, 1152, 427, 1769, 661, 267, 9022, 19...   \n",
       "39  [44, 4026, 1152, 427, 1769, 661, 267, 22191, 1...   \n",
       "40  [44, 4026, 1152, 427, 1769, 661, 267, 2910, 10...   \n",
       "41  [44, 4026, 1152, 427, 1769, 661, 267, 230674, ...   \n",
       "42  [44, 4026, 1152, 427, 1769, 661, 267, 48488, 6...   \n",
       "43  [44, 4026, 1152, 427, 1769, 661, 267, 6848, 94...   \n",
       "44  [44, 4026, 1152, 427, 1769, 661, 660, 75299, 1...   \n",
       "45  [44, 4026, 1152, 427, 1769, 661, 267, 27738, 5...   \n",
       "46  [44, 4026, 1152, 427, 1769, 661, 660, 13538, 4...   \n",
       "47  [44, 12865, 20886, 5268, 1400, 12580, 192316, ...   \n",
       "48  [95694, 57624, 1002, 116270, 664, 215903, 3669...   \n",
       "49  [44, 4026, 1152, 427, 1769, 661, 660, 53292, 2...   \n",
       "\n",
       "                                       attention_mask  \n",
       "0   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "1   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "2   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "3   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "4   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "5   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "6   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "7   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "8   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "9   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "10  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "11  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "12  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "13  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "14  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "15  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "16  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "17  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "18  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "19  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "20  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "21  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "22  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "23  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "24  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "25  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "26  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "27  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "28  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "29  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "30  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "31  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "32  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "33  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "34  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "35  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "36  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "37  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "38  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "39  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "40  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "41  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "42  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "43  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "44  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "45  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "46  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "47  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "48  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "49  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(train_sample_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask'],\n",
       "    num_rows: 25\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## prepare a second dataset \n",
    "dataset_sentences = load_dataset('Abirate/english_quotes')\n",
    "\n",
    "data_sentences = dataset_sentences.map(lambda samples:tokenizer(samples['quote']), batched = True)\n",
    "train_sample_sentences = data_sentences['train'].select(range(25))\n",
    "train_sample_sentences = train_sample_sentences.remove_columns(['quote','author','tags'])\n",
    "display(train_sample_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1502, 17143, 33218, 30, 39839, 4384, 632, 112...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1502, 10203, 239002, 15, 136192, 1049, 530, 2...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1502, 35417, 11217, 1306, 61759, 29, 368, 713...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1502, 6895, 7112, 38695, 15, 1427, 10512, 350...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[119533, 22630, 7160, 38695, 632, 3269, 267, 1...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[1502, 17143, 5268, 1152, 1306, 530, 5894, 359...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[1502, 124002, 83213, 59020, 3269, 20242, 8839...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[1502, 5448, 4472, 11700, 361, 19134, 3262, 11...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[1502, 5448, 3804, 20152, 14275, 15, 1965, 132...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[1502, 17143, 368, 7458, 861, 1152, 26338, 427...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[1502, 1411, 8603, 17848, 473, 1400, 6129, 225...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[1502, 7690, 1152, 4026, 427, 4472, 3595, 267,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[1502, 19908, 763, 51794, 109010, 87, 29497, 3...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[1502, 7690, 1152, 13485, 368, 40267, 15, 1152...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[1502, 214469, 35050, 2815, 632, 34181, 919, 3...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[119533, 24015, 632, 20886, 5268, 45406, 1728,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[1502, 171790, 168682, 2632, 120960, 30, 16915...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[1502, 4670, 20152, 632, 368, 40094, 388, 1173...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[1502, 81276, 661, 1320, 1152, 3121, 427, 6765...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[1502, 162312, 8071, 12562, 26150, 1800, 12851...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[1502, 97797, 23444, 15, 10440, 3276, 722, 267...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[1502, 7994, 14390, 368, 19134, 1701, 6482, 17...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[123916, 912, 1427, 149014, 861, 28077, 473, 5...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[1502, 4670, 722, 33218, 361, 267, 8876, 861, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[1502, 45308, 427, 368, 85105, 26696, 17, 1387...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            input_ids  \\\n",
       "0   [1502, 17143, 33218, 30, 39839, 4384, 632, 112...   \n",
       "1   [1502, 10203, 239002, 15, 136192, 1049, 530, 2...   \n",
       "2   [1502, 35417, 11217, 1306, 61759, 29, 368, 713...   \n",
       "3   [1502, 6895, 7112, 38695, 15, 1427, 10512, 350...   \n",
       "4   [119533, 22630, 7160, 38695, 632, 3269, 267, 1...   \n",
       "5   [1502, 17143, 5268, 1152, 1306, 530, 5894, 359...   \n",
       "6   [1502, 124002, 83213, 59020, 3269, 20242, 8839...   \n",
       "7   [1502, 5448, 4472, 11700, 361, 19134, 3262, 11...   \n",
       "8   [1502, 5448, 3804, 20152, 14275, 15, 1965, 132...   \n",
       "9   [1502, 17143, 368, 7458, 861, 1152, 26338, 427...   \n",
       "10  [1502, 1411, 8603, 17848, 473, 1400, 6129, 225...   \n",
       "11  [1502, 7690, 1152, 4026, 427, 4472, 3595, 267,...   \n",
       "12  [1502, 19908, 763, 51794, 109010, 87, 29497, 3...   \n",
       "13  [1502, 7690, 1152, 13485, 368, 40267, 15, 1152...   \n",
       "14  [1502, 214469, 35050, 2815, 632, 34181, 919, 3...   \n",
       "15  [119533, 24015, 632, 20886, 5268, 45406, 1728,...   \n",
       "16  [1502, 171790, 168682, 2632, 120960, 30, 16915...   \n",
       "17  [1502, 4670, 20152, 632, 368, 40094, 388, 1173...   \n",
       "18  [1502, 81276, 661, 1320, 1152, 3121, 427, 6765...   \n",
       "19  [1502, 162312, 8071, 12562, 26150, 1800, 12851...   \n",
       "20  [1502, 97797, 23444, 15, 10440, 3276, 722, 267...   \n",
       "21  [1502, 7994, 14390, 368, 19134, 1701, 6482, 17...   \n",
       "22  [123916, 912, 1427, 149014, 861, 28077, 473, 5...   \n",
       "23  [1502, 4670, 722, 33218, 361, 267, 8876, 861, ...   \n",
       "24  [1502, 45308, 427, 368, 85105, 26696, 17, 1387...   \n",
       "\n",
       "                                       attention_mask  \n",
       "0                   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  \n",
       "1   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "2   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "3                      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  \n",
       "4             [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  \n",
       "5   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "6   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "7   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "8   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "9          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  \n",
       "10  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "11  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "12  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "13      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  \n",
       "14  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "15      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  \n",
       "16         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  \n",
       "17  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "18  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "19  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "20                  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  \n",
       "21                  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  \n",
       "22  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "23  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "24  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(train_sample_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "## time to fine tune with Parameter Efficient Fine Tuning\n",
    "from peft import get_peft_model, PromptTuningConfig, TaskType, PromptTuningInit\n",
    "\n",
    "generator_config = PromptTuningConfig(\n",
    "    task_type = TaskType.CAUSAL_LM, # this makes the model generate text\n",
    "    prompt_tuning_init = PromptTuningInit.RANDOM, # initialise the virtual tokens with random numbers\n",
    "    num_virtual_tokens = NUM_VIRTUAL_TOKENS, # number of virtual tokens to add and train\n",
    "    tokenizer_name_or_path = model_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 10,240 || all params: 559,224,832 || trainable%: 0.0018311060979495275\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "peft_model_prompt = get_peft_model(foundational_model, generator_config)\n",
    "print(peft_model_prompt.print_trainable_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 10,240 || all params: 559,224,832 || trainable%: 0.0018311060979495275\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "peft_model_sentences = get_peft_model(foundational_model, generator_config)\n",
    "print(peft_model_sentences.print_trainable_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "## start to create the training configuration\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "def create_training_arguments(path, learning_rate = 0.0035, epochs = 6):\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir = path,\n",
    "        auto_find_batch_size = True,\n",
    "        learning_rate = learning_rate,\n",
    "        num_train_epochs = epochs\n",
    "    )\n",
    "\n",
    "    return training_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create directories to hold the model when they don't exist\n",
    "\n",
    "working_dir = './peft'\n",
    "\n",
    "## it is recommended to store the models seperately\n",
    "output_dir_prompt = os.path.join(working_dir, 'peft_outputs_prompt')\n",
    "output_dir_sentences = os.path.join(working_dir, 'peft_outputs_sentences')\n",
    "\n",
    "## create the directories if they don't exist\n",
    "if not os.path.exists(working_dir):\n",
    "    os.mkdir(working_dir)\n",
    "if not os.path.exists(output_dir_prompt):\n",
    "    os.mkdir(output_dir_prompt)\n",
    "if not os.path.exists(output_dir_sentences):\n",
    "    os.mkdir(output_dir_sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args_prompt = create_training_arguments(output_dir_prompt, 0.003, NUM_EPOCHS)\n",
    "training_args_sentences = create_training_arguments(output_dir_sentences, 0.0035, NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, DataCollatorForLanguageModeling \n",
    "\n",
    "def create_trainer(model, training_args, train_dataset):\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args = training_args,\n",
    "        train_dataset = train_dataset,\n",
    "        data_collator = DataCollatorForLanguageModeling(tokenizer, mlm = False)\n",
    "    )\n",
    "\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 01:30, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:41, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5, training_loss=4.071768188476563, metrics={'train_runtime': 51.5815, 'train_samples_per_second': 2.423, 'train_steps_per_second': 0.097, 'total_flos': 28795358208000.0, 'train_loss': 4.071768188476563, 'epoch': 5.0})"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## time to finetune the models\n",
    "trainer_prompt = create_trainer(peft_model_prompt, training_args_prompt, train_sample_prompt)\n",
    "trainer_prompt.train()\n",
    "\n",
    "trainer_sentences = create_trainer(peft_model_sentences, training_args_sentences, train_sample_sentences)\n",
    "trainer_sentences.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save the models\n",
    "trainer_prompt.model.save_pretrained(output_dir_prompt)\n",
    "trainer_sentences.model.save_pretrained(output_dir_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "\n",
    "loaded_model_prompt = PeftModel.from_pretrained(foundational_model,\n",
    "                                         output_dir_prompt,\n",
    "                                         #device_map='auto',\n",
    "                                         is_trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I want you to act as a motivational coach. Learn how to be a motivational coach']\n"
     ]
    }
   ],
   "source": [
    "## inference\n",
    "loaded_model_prompt_outputs = get_outputs(loaded_model_prompt, input_prompt)\n",
    "print(tokenizer.batch_decode(loaded_model_prompt_outputs, skip_special_tokens = True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I want you to act as a motivational coach. I want you to be a motivational coach.']\n"
     ]
    }
   ],
   "source": [
    "## inference\n",
    "loaded_model_prompt_outputs = get_outputs(loaded_model_prompt, input_prompt)\n",
    "print(tokenizer.batch_decode(loaded_model_prompt_outputs, skip_special_tokens = True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I want you to act as a motivational coach. I want you to be a motivational coach.']\n"
     ]
    }
   ],
   "source": [
    "## inference\n",
    "loaded_model_prompt_outputs = get_outputs(loaded_model_prompt, input_prompt)\n",
    "print(tokenizer.batch_decode(loaded_model_prompt_outputs, skip_special_tokens = True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model_sentences = PeftModel.from_pretrained(foundational_model,\n",
    "                                         output_dir_sentences,\n",
    "                                         #device_map='auto',\n",
    "                                         is_trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['There are two things that matter: income and wealth.']\n"
     ]
    }
   ],
   "source": [
    "## inference\n",
    "loaded_model_sentences_outputs = get_outputs(loaded_model_sentences, input_sentences)\n",
    "print(tokenizer.batch_decode(loaded_model_sentences_outputs, skip_special_tokens = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['There are two things that matter: time and money.']\n"
     ]
    }
   ],
   "source": [
    "## inference\n",
    "loaded_model_sentences_outputs = get_outputs(loaded_model_sentences, input_sentences)\n",
    "print(tokenizer.batch_decode(loaded_model_sentences_outputs, skip_special_tokens = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['There are two things that matter: time and money.']\n"
     ]
    }
   ],
   "source": [
    "## inference\n",
    "loaded_model_sentences_outputs = get_outputs(loaded_model_sentences, input_sentences)\n",
    "print(tokenizer.batch_decode(loaded_model_sentences_outputs, skip_special_tokens = True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
