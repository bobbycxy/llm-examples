{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bobby/code-repo/practices/llm-examples/env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 2,359,296 || all params: 1,231,940,608 || trainable%: 0.19151053100118282\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'trainable params: 2359296 || all params: 1231940608 || trainable%: 0.19151053100118282'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "from peft import get_peft_config, get_peft_model, LoraConfig, TaskType\n",
    "model_name_or_path = \"bigscience/mt0-large\"\n",
    "tokenizer_name_or_path = \"bigscience/mt0-large\"\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM, inference_mode=False, r=8, lora_alpha=32, lora_dropout=0.1\n",
    ")\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name_or_path)\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()\n",
    "\"trainable params: 2359296 || all params: 1231940608 || trainable%: 0.19151053100118282\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preheat the oven to 350 degrees and place the cookie dough in the center of the oven.\n",
      "\n",
      "In a large bowl, combine the flour, baking powder, baking soda, salt, and cinnamon.\n",
      "\n",
      "In a separate bowl, combine the egg yolks, sugar, and vanilla.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from peft import AutoPeftModelForCausalLM\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "\n",
    "model = AutoPeftModelForCausalLM.from_pretrained(\"ybelkada/opt-350m-lora\").to(\"cuda\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-350m\")\n",
    "\n",
    "model.eval()\n",
    "inputs = tokenizer(\"Preheat the oven to 350 degrees and place the cookie dough\", return_tensors=\"pt\")\n",
    "\n",
    "outputs = model.generate(input_ids=inputs[\"input_ids\"].to(\"cuda\"), max_new_tokens=50)\n",
    "print(tokenizer.batch_decode(outputs, skip_special_tokens=True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "from peft import get_peft_config, get_peft_model, PromptTuningInit, PromptTuningConfig, TaskType, PeftType\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "import os\n",
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import default_data_collator, get_linear_schedule_with_warmup\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset\n",
    "\n",
    "device = \"cuda\"\n",
    "model_name_or_path = \"bigscience/bloomz-560m\"\n",
    "tokenizer_name_or_path = \"bigscience/bloomz-560m\"\n",
    "peft_config = PromptTuningConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    prompt_tuning_init=PromptTuningInit.TEXT,\n",
    "    num_virtual_tokens=8,\n",
    "    prompt_tuning_init_text=\"Classify if the tweet is a complaint or not:\",\n",
    "    tokenizer_name_or_path=model_name_or_path,\n",
    ")\n",
    "\n",
    "dataset_name = \"twitter_complaints\"\n",
    "checkpoint_name = f\"{dataset_name}_{model_name_or_path}_{peft_config.peft_type}_{peft_config.task_type}_v1.pt\".replace(\n",
    "    \"/\", \"_\"\n",
    ")\n",
    "text_column = \"Tweet text\"\n",
    "label_column = \"text_label\"\n",
    "max_length = 64\n",
    "lr = 3e-2\n",
    "num_epochs = 50\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Unlabeled', 'complaint', 'no complaint']\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['Tweet text', 'ID', 'Label', 'text_label'],\n",
      "        num_rows: 50\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['Tweet text', 'ID', 'Label', 'text_label'],\n",
      "        num_rows: 3399\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Tweet text': '@HMRCcustomers No this is my first job',\n",
       " 'ID': 0,\n",
       " 'Label': 2,\n",
       " 'text_label': 'no complaint'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"ought/raft\", dataset_name)\n",
    "\n",
    "classes = [k.replace(\"_\", \" \") for k in dataset[\"train\"].features[\"Label\"].names]\n",
    "print(classes)\n",
    "dataset = dataset.map(\n",
    "    lambda x: {\"text_label\": [classes[label] for label in x[\"Label\"]]},\n",
    "    batched=True,\n",
    "    num_proc=1,\n",
    ")\n",
    "print(dataset)\n",
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running tokenizer on dataset: 100%|██████████| 50/50 [00:00<00:00, 3868.93 examples/s]\n",
      "Running tokenizer on dataset: 100%|██████████| 3399/3399 [00:00<00:00, 10602.49 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# data preprocessing\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "if tokenizer.pad_token_id is None:\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "target_max_length = max([len(tokenizer(class_label)[\"input_ids\"]) for class_label in classes])\n",
    "print(target_max_length)\n",
    "\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    batch_size = len(examples[text_column])\n",
    "    inputs = [f\"{text_column} : {x} Label : \" for x in examples[text_column]]\n",
    "    targets = [str(x) for x in examples[label_column]]\n",
    "    model_inputs = tokenizer(inputs)\n",
    "    labels = tokenizer(targets, add_special_tokens=False)  # don't add bos token because we concatenate with inputs\n",
    "    for i in range(batch_size):\n",
    "        sample_input_ids = model_inputs[\"input_ids\"][i]\n",
    "        label_input_ids = labels[\"input_ids\"][i] + [tokenizer.eos_token_id]\n",
    "        # print(i, sample_input_ids, label_input_ids)\n",
    "        model_inputs[\"input_ids\"][i] = sample_input_ids + label_input_ids\n",
    "        labels[\"input_ids\"][i] = [-100] * len(sample_input_ids) + label_input_ids\n",
    "        model_inputs[\"attention_mask\"][i] = [1] * len(model_inputs[\"input_ids\"][i])\n",
    "    # print(model_inputs)\n",
    "    for i in range(batch_size):\n",
    "        sample_input_ids = model_inputs[\"input_ids\"][i]\n",
    "        label_input_ids = labels[\"input_ids\"][i]\n",
    "        model_inputs[\"input_ids\"][i] = [tokenizer.pad_token_id] * (\n",
    "            max_length - len(sample_input_ids)\n",
    "        ) + sample_input_ids\n",
    "        model_inputs[\"attention_mask\"][i] = [0] * (max_length - len(sample_input_ids)) + model_inputs[\n",
    "            \"attention_mask\"\n",
    "        ][i]\n",
    "        labels[\"input_ids\"][i] = [-100] * (max_length - len(sample_input_ids)) + label_input_ids\n",
    "        model_inputs[\"input_ids\"][i] = torch.tensor(model_inputs[\"input_ids\"][i][:max_length])\n",
    "        model_inputs[\"attention_mask\"][i] = torch.tensor(model_inputs[\"attention_mask\"][i][:max_length])\n",
    "        labels[\"input_ids\"][i] = torch.tensor(labels[\"input_ids\"][i][:max_length])\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "\n",
    "processed_datasets = dataset.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    num_proc=1,\n",
    "    remove_columns=dataset[\"train\"].column_names,\n",
    "    load_from_cache_file=False,\n",
    "    desc=\"Running tokenizer on dataset\",\n",
    ")\n",
    "\n",
    "train_dataset = processed_datasets[\"train\"]\n",
    "eval_dataset = processed_datasets[\"train\"]\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, shuffle=True, collate_fn=default_data_collator, batch_size=batch_size, pin_memory=True\n",
    ")\n",
    "eval_dataloader = DataLoader(eval_dataset, collate_fn=default_data_collator, batch_size=batch_size, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running tokenizer on dataset: 100%|██████████| 3399/3399 [00:00<00:00, 22844.84 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[     3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
       "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
       "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
       "          227985,   5484,    915,   2566,  74757,  64626,  12384,  44639,    613,\n",
       "           52282,   2670,  79920,   3344,   1002,    368,  17646,  14472,   8348,\n",
       "             664,    718,      4,  19036,     17,  31849,     17,   6312,     76,\n",
       "              44,  62470,     56,     91,     50,  14839,     21,  77658,    915,\n",
       "             210],\n",
       "         [     3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
       "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
       "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
       "               3,      3,      3,      3, 227985,   5484,    915,    405, 187059,\n",
       "            2256,    664,   2550,  18833,  18607, 162467,      4,   1387,   6199,\n",
       "            3291,  23405,    613,   4657,  17082,    566,   3432,    368,  78851,\n",
       "            1185,  61273,  23181,   1553,  15596,    212, 116057,  77658,    915,\n",
       "             210],\n",
       "         [     3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
       "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
       "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
       "               3,      3,      3,      3,      3,      3,      3, 227985,   5484,\n",
       "             915,  39762,   2566,  22253,   6201,  75701,     15,    632,    718,\n",
       "            5840,  10006,   6201,  18881,    427,   3804,  19528,    267, 158974,\n",
       "            1320,    368,  10029,    632,  49666,     92,     34,  77658,    915,\n",
       "             210],\n",
       "         [     3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
       "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
       "               3, 227985,   5484,    915,   2566, 104565,   8695,   2089,   6140,\n",
       "          109676,  99579,   1369,    512,    368,   4570,     54,    632,    368,\n",
       "            1503, 241485, 132226,     15,    982,    727,   1152,  18100,    861,\n",
       "           32596,  77597, 168154,   1306, 132226,   4346,  87843,     17, 130462,\n",
       "             364,  32923,     89,     53,   8309,     20,     75,  77658,    915,\n",
       "             210],\n",
       "         [     3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
       "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
       "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
       "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
       "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
       "               3,      3,      3,      3,      3, 227985,   5484,    915,   2566,\n",
       "           14173,   2960,  29906,    387,  20706,  49337,   1369,  77658,    915,\n",
       "             210],\n",
       "         [     3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
       "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
       "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
       "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
       "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
       "               3,      3,      3, 227985,   5484,    915,   2566, 219553,  45736,\n",
       "           36876,   1713,     72,    707, 187205,  13002, 177324,  77658,    915,\n",
       "             210],\n",
       "         [     3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
       "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
       "               3,      3, 227985,   5484,    915,   2566, 233938,  28518,  13716,\n",
       "             427,  28146,   1119,  17918,     17, 236706,    368, 214997,   7555,\n",
       "           48659,   5276,  21600,    343,     17,  51416,  22403,    318,   1531,\n",
       "            1306,   1130,  20934,    567, 101161, 184849,  87843,     17,   1594,\n",
       "           15231,   2052,  16642,     20,   7180,     80,     26,  77658,    915,\n",
       "             210],\n",
       "         [     3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
       "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
       "          227985,   5484,    915,   2566,     80,   2068,    479,   2566,     80,\n",
       "            1376,    878, 147587,   3904,    632,    368,   6084,  65673,  78851,\n",
       "           11736,  15527,  19082,  33151,    461,     17,  45575,  17887,    632,\n",
       "            5219,  14216,  68870,   5967,   1841,   4346,  87843,     17,   1594,\n",
       "           14512,     27,     71,   8184,     19,    290,  63748,  77658,    915,\n",
       "             210]]),\n",
       " 'attention_mask': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_preprocess_function(examples):\n",
    "    batch_size = len(examples[text_column])\n",
    "    inputs = [f\"{text_column} : {x} Label : \" for x in examples[text_column]]\n",
    "    model_inputs = tokenizer(inputs)\n",
    "    # print(model_inputs)\n",
    "    for i in range(batch_size):\n",
    "        sample_input_ids = model_inputs[\"input_ids\"][i]\n",
    "        model_inputs[\"input_ids\"][i] = [tokenizer.pad_token_id] * (\n",
    "            max_length - len(sample_input_ids)\n",
    "        ) + sample_input_ids\n",
    "        model_inputs[\"attention_mask\"][i] = [0] * (max_length - len(sample_input_ids)) + model_inputs[\n",
    "            \"attention_mask\"\n",
    "        ][i]\n",
    "        model_inputs[\"input_ids\"][i] = torch.tensor(model_inputs[\"input_ids\"][i][:max_length])\n",
    "        model_inputs[\"attention_mask\"][i] = torch.tensor(model_inputs[\"attention_mask\"][i][:max_length])\n",
    "    return model_inputs\n",
    "\n",
    "\n",
    "test_dataset = dataset[\"test\"].map(\n",
    "    test_preprocess_function,\n",
    "    batched=True,\n",
    "    num_proc=1,\n",
    "    remove_columns=dataset[\"train\"].column_names,\n",
    "    load_from_cache_file=False,\n",
    "    desc=\"Running tokenizer on dataset\",\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, collate_fn=default_data_collator, batch_size=batch_size, pin_memory=True)\n",
    "next(iter(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[     3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
       "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
       "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
       "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
       "               3,      3,      3,      3,      3, 227985,   5484,    915,   2566,\n",
       "           17785,  45614,  19985,   1400,  14831,  45614,    973,     55,    727,\n",
       "           11571,  37643,  65221,     34,  77658,    915,    210,   1936, 106863,\n",
       "               2],\n",
       "         [     3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
       "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
       "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
       "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
       "               3,      3, 227985,   5484,    915,   2566, 181601,  62835,   6640,\n",
       "            1935,    210,    654,  10144,    361,  21479,    300,  10583,   1369,\n",
       "             632,    718,  86109,     17,  77658,    915,    210,  16449,   5952,\n",
       "               2],\n",
       "         [     3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
       "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
       "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
       "               3,      3,      3,      3,      3, 227985,   5484,    915,   2566,\n",
       "           57647,    327,  38804,     86,  35631,    368,   7733,   4676,    427,\n",
       "           10665,  57903,    664,    267,   6917,  18706,    427,    368,  16698,\n",
       "           35633,   3383,  27409,     34,  77658,    915,    210,   1936, 106863,\n",
       "               2],\n",
       "         [     3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
       "               3,      3,      3, 227985,   5484,    915,   5161,  13500,    386,\n",
       "               4, 122906,    415,  66027,  42431,    613,  70016,    361,   2550,\n",
       "              51,  21351,    322,  17896,     15,   2550,     49,     45,   2550,\n",
       "           21450,    388,    655,   2550,     75,  14263,    916,     86,   1881,\n",
       "           36534,  53902,      4,   4346,  87843,     17, 130462,   8188,     23,\n",
       "            5949, 187347,     78, 130589,  77658,    915,    210,   1936, 106863,\n",
       "               2],\n",
       "         [     3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
       "               3,      3,      3, 227985,   5484,    915,  43504,  51648,   5456,\n",
       "          176088,     34,  57180,  28627,    269,  13041,   2566, 114242,    672,\n",
       "            2338,  56114,    427,   4054,    530, 182640,   7963,    427,  19134,\n",
       "             718,      4,   2550,  55061,  17209,   2550, 114242,    672,   9702,\n",
       "              90,    647,   4346,  87843,     17, 130462,  40081,  10881,     73,\n",
       "              84,     38,    624,     43,  77658,    915,    210,   1936, 106863,\n",
       "               2],\n",
       "         [     3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
       "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
       "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
       "               3, 227985,   5484,    915,   2566,    296,   3143,   5990,   1475,\n",
       "            1026,      4,   3162,   3403,   6440,   1152,    267,  57733,   1002,\n",
       "            2632,  31335,   9313,   4040,    530,   3595,   3509,   3291, 137057,\n",
       "             722,  33766,   2256,      4,  77658,    915,    210,   1936, 106863,\n",
       "               2],\n",
       "         [     3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
       "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
       "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
       "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
       "               3,      3,      3,      3,      3,      3,      3,      3, 227985,\n",
       "            5484,    915,   2566, 169403,  15296,  36272,    525,   3928,   1119,\n",
       "             632,   2670,   3968,  15270,  77658,    915,    210,   1936, 106863,\n",
       "               2],\n",
       "         [     3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
       "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
       "               3,      3,      3,      3,      3,      3,      3,      3, 227985,\n",
       "            5484,    915, 191971,    261,  74182,      4, 226928,    427,  25608,\n",
       "            1002,  39839,    473,   4472,   2550,     41,  86461,   4352,  19821,\n",
       "            2550, 238683,  13663,  87843,     17,   1594,  14663,     36,     52,\n",
       "              44,   6794,     81,  87781,  77658,    915,    210,   1936, 106863,\n",
       "               2]]),\n",
       " 'attention_mask': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]),\n",
       " 'labels': tensor([[  -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   1936, 106863,\n",
       "               2],\n",
       "         [  -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "            -100,   -100,   -100,   -100,   -100,   -100,   -100,  16449,   5952,\n",
       "               2],\n",
       "         [  -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   1936, 106863,\n",
       "               2],\n",
       "         [  -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   1936, 106863,\n",
       "               2],\n",
       "         [  -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   1936, 106863,\n",
       "               2],\n",
       "         [  -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   1936, 106863,\n",
       "               2],\n",
       "         [  -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   1936, 106863,\n",
       "               2],\n",
       "         [  -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   1936, 106863,\n",
       "               2]])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "425"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[     3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
       "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
       "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
       "          227985,   5484,    915,   2566,  74757,  64626,  12384,  44639,    613,\n",
       "           52282,   2670,  79920,   3344,   1002,    368,  17646,  14472,   8348,\n",
       "             664,    718,      4,  19036,     17,  31849,     17,   6312,     76,\n",
       "              44,  62470,     56,     91,     50,  14839,     21,  77658,    915,\n",
       "             210],\n",
       "         [     3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
       "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
       "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
       "               3,      3,      3,      3, 227985,   5484,    915,    405, 187059,\n",
       "            2256,    664,   2550,  18833,  18607, 162467,      4,   1387,   6199,\n",
       "            3291,  23405,    613,   4657,  17082,    566,   3432,    368,  78851,\n",
       "            1185,  61273,  23181,   1553,  15596,    212, 116057,  77658,    915,\n",
       "             210],\n",
       "         [     3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
       "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
       "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
       "               3,      3,      3,      3,      3,      3,      3, 227985,   5484,\n",
       "             915,  39762,   2566,  22253,   6201,  75701,     15,    632,    718,\n",
       "            5840,  10006,   6201,  18881,    427,   3804,  19528,    267, 158974,\n",
       "            1320,    368,  10029,    632,  49666,     92,     34,  77658,    915,\n",
       "             210],\n",
       "         [     3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
       "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
       "               3, 227985,   5484,    915,   2566, 104565,   8695,   2089,   6140,\n",
       "          109676,  99579,   1369,    512,    368,   4570,     54,    632,    368,\n",
       "            1503, 241485, 132226,     15,    982,    727,   1152,  18100,    861,\n",
       "           32596,  77597, 168154,   1306, 132226,   4346,  87843,     17, 130462,\n",
       "             364,  32923,     89,     53,   8309,     20,     75,  77658,    915,\n",
       "             210],\n",
       "         [     3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
       "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
       "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
       "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
       "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
       "               3,      3,      3,      3,      3, 227985,   5484,    915,   2566,\n",
       "           14173,   2960,  29906,    387,  20706,  49337,   1369,  77658,    915,\n",
       "             210],\n",
       "         [     3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
       "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
       "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
       "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
       "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
       "               3,      3,      3, 227985,   5484,    915,   2566, 219553,  45736,\n",
       "           36876,   1713,     72,    707, 187205,  13002, 177324,  77658,    915,\n",
       "             210],\n",
       "         [     3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
       "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
       "               3,      3, 227985,   5484,    915,   2566, 233938,  28518,  13716,\n",
       "             427,  28146,   1119,  17918,     17, 236706,    368, 214997,   7555,\n",
       "           48659,   5276,  21600,    343,     17,  51416,  22403,    318,   1531,\n",
       "            1306,   1130,  20934,    567, 101161, 184849,  87843,     17,   1594,\n",
       "           15231,   2052,  16642,     20,   7180,     80,     26,  77658,    915,\n",
       "             210],\n",
       "         [     3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
       "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
       "          227985,   5484,    915,   2566,     80,   2068,    479,   2566,     80,\n",
       "            1376,    878, 147587,   3904,    632,    368,   6084,  65673,  78851,\n",
       "           11736,  15527,  19082,  33151,    461,     17,  45575,  17887,    632,\n",
       "            5219,  14216,  68870,   5967,   1841,   4346,  87843,     17,   1594,\n",
       "           14512,     27,     71,   8184,     19,    290,  63748,  77658,    915,\n",
       "             210]]),\n",
       " 'attention_mask': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 8,192 || all params: 559,222,784 || trainable%: 0.0014648902430985358\n"
     ]
    }
   ],
   "source": [
    "# creating model\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name_or_path)\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "# optimizer and lr scheduler\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "lr_scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=(len(train_dataloader) * num_epochs),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.70it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 16.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0: train_ppl=tensor(169.6392, device='cuda:0') train_epoch_loss=tensor(5.1337, device='cuda:0') eval_ppl=tensor(14.8705, device='cuda:0') eval_epoch_loss=tensor(2.6994, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.70it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 16.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=1: train_ppl=tensor(4.6824, device='cuda:0') train_epoch_loss=tensor(1.5438, device='cuda:0') eval_ppl=tensor(1.8336, device='cuda:0') eval_epoch_loss=tensor(0.6063, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.65it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 16.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=2: train_ppl=tensor(1.5433, device='cuda:0') train_epoch_loss=tensor(0.4339, device='cuda:0') eval_ppl=tensor(1.3311, device='cuda:0') eval_epoch_loss=tensor(0.2860, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.63it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 16.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=3: train_ppl=tensor(1.4895, device='cuda:0') train_epoch_loss=tensor(0.3984, device='cuda:0') eval_ppl=tensor(1.3325, device='cuda:0') eval_epoch_loss=tensor(0.2870, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.62it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 16.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=4: train_ppl=tensor(1.3169, device='cuda:0') train_epoch_loss=tensor(0.2753, device='cuda:0') eval_ppl=tensor(1.2667, device='cuda:0') eval_epoch_loss=tensor(0.2364, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.63it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 16.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=5: train_ppl=tensor(1.2411, device='cuda:0') train_epoch_loss=tensor(0.2160, device='cuda:0') eval_ppl=tensor(1.3511, device='cuda:0') eval_epoch_loss=tensor(0.3009, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.61it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 16.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=6: train_ppl=tensor(1.2632, device='cuda:0') train_epoch_loss=tensor(0.2336, device='cuda:0') eval_ppl=tensor(1.2540, device='cuda:0') eval_epoch_loss=tensor(0.2264, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.60it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 15.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=7: train_ppl=tensor(1.2650, device='cuda:0') train_epoch_loss=tensor(0.2351, device='cuda:0') eval_ppl=tensor(1.2508, device='cuda:0') eval_epoch_loss=tensor(0.2238, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.63it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 16.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=8: train_ppl=tensor(1.2280, device='cuda:0') train_epoch_loss=tensor(0.2054, device='cuda:0') eval_ppl=tensor(1.2282, device='cuda:0') eval_epoch_loss=tensor(0.2055, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.66it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 16.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=9: train_ppl=tensor(1.2219, device='cuda:0') train_epoch_loss=tensor(0.2004, device='cuda:0') eval_ppl=tensor(1.2110, device='cuda:0') eval_epoch_loss=tensor(0.1915, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.63it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 16.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=10: train_ppl=tensor(1.2067, device='cuda:0') train_epoch_loss=tensor(0.1879, device='cuda:0') eval_ppl=tensor(1.2098, device='cuda:0') eval_epoch_loss=tensor(0.1905, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.61it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 16.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=11: train_ppl=tensor(1.1836, device='cuda:0') train_epoch_loss=tensor(0.1686, device='cuda:0') eval_ppl=tensor(1.1935, device='cuda:0') eval_epoch_loss=tensor(0.1769, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.60it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 16.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=12: train_ppl=tensor(1.1948, device='cuda:0') train_epoch_loss=tensor(0.1780, device='cuda:0') eval_ppl=tensor(1.1990, device='cuda:0') eval_epoch_loss=tensor(0.1815, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.60it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 16.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=13: train_ppl=tensor(1.1827, device='cuda:0') train_epoch_loss=tensor(0.1678, device='cuda:0') eval_ppl=tensor(1.1776, device='cuda:0') eval_epoch_loss=tensor(0.1634, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.58it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 16.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=14: train_ppl=tensor(1.1556, device='cuda:0') train_epoch_loss=tensor(0.1446, device='cuda:0') eval_ppl=tensor(1.1795, device='cuda:0') eval_epoch_loss=tensor(0.1651, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.60it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 16.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=15: train_ppl=tensor(1.1612, device='cuda:0') train_epoch_loss=tensor(0.1495, device='cuda:0') eval_ppl=tensor(1.1606, device='cuda:0') eval_epoch_loss=tensor(0.1489, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.58it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 15.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=16: train_ppl=tensor(1.1683, device='cuda:0') train_epoch_loss=tensor(0.1556, device='cuda:0') eval_ppl=tensor(1.1880, device='cuda:0') eval_epoch_loss=tensor(0.1723, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.60it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 16.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=17: train_ppl=tensor(1.1498, device='cuda:0') train_epoch_loss=tensor(0.1396, device='cuda:0') eval_ppl=tensor(1.1602, device='cuda:0') eval_epoch_loss=tensor(0.1486, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.58it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 16.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=18: train_ppl=tensor(1.1917, device='cuda:0') train_epoch_loss=tensor(0.1753, device='cuda:0') eval_ppl=tensor(1.1884, device='cuda:0') eval_epoch_loss=tensor(0.1726, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.55it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 15.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=19: train_ppl=tensor(1.1346, device='cuda:0') train_epoch_loss=tensor(0.1263, device='cuda:0') eval_ppl=tensor(1.1460, device='cuda:0') eval_epoch_loss=tensor(0.1363, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.54it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 15.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=20: train_ppl=tensor(1.1468, device='cuda:0') train_epoch_loss=tensor(0.1369, device='cuda:0') eval_ppl=tensor(1.1340, device='cuda:0') eval_epoch_loss=tensor(0.1258, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.52it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 15.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=21: train_ppl=tensor(1.1031, device='cuda:0') train_epoch_loss=tensor(0.0981, device='cuda:0') eval_ppl=tensor(1.1180, device='cuda:0') eval_epoch_loss=tensor(0.1115, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.54it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 15.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=22: train_ppl=tensor(1.1123, device='cuda:0') train_epoch_loss=tensor(0.1064, device='cuda:0') eval_ppl=tensor(1.0985, device='cuda:0') eval_epoch_loss=tensor(0.0939, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.51it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 15.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=23: train_ppl=tensor(1.0966, device='cuda:0') train_epoch_loss=tensor(0.0922, device='cuda:0') eval_ppl=tensor(1.1177, device='cuda:0') eval_epoch_loss=tensor(0.1112, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.50it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 15.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=24: train_ppl=tensor(1.1042, device='cuda:0') train_epoch_loss=tensor(0.0991, device='cuda:0') eval_ppl=tensor(1.1062, device='cuda:0') eval_epoch_loss=tensor(0.1009, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.51it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 15.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=25: train_ppl=tensor(1.0955, device='cuda:0') train_epoch_loss=tensor(0.0912, device='cuda:0') eval_ppl=tensor(1.0717, device='cuda:0') eval_epoch_loss=tensor(0.0692, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.50it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 15.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=26: train_ppl=tensor(1.0702, device='cuda:0') train_epoch_loss=tensor(0.0679, device='cuda:0') eval_ppl=tensor(1.0631, device='cuda:0') eval_epoch_loss=tensor(0.0611, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.45it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 15.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=27: train_ppl=tensor(1.0708, device='cuda:0') train_epoch_loss=tensor(0.0684, device='cuda:0') eval_ppl=tensor(1.0514, device='cuda:0') eval_epoch_loss=tensor(0.0502, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.43it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 15.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=28: train_ppl=tensor(1.0507, device='cuda:0') train_epoch_loss=tensor(0.0494, device='cuda:0') eval_ppl=tensor(1.0584, device='cuda:0') eval_epoch_loss=tensor(0.0567, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.44it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 15.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=29: train_ppl=tensor(1.0580, device='cuda:0') train_epoch_loss=tensor(0.0564, device='cuda:0') eval_ppl=tensor(1.0417, device='cuda:0') eval_epoch_loss=tensor(0.0408, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.44it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 15.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=30: train_ppl=tensor(1.0451, device='cuda:0') train_epoch_loss=tensor(0.0441, device='cuda:0') eval_ppl=tensor(1.0360, device='cuda:0') eval_epoch_loss=tensor(0.0354, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.42it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 15.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=31: train_ppl=tensor(1.0538, device='cuda:0') train_epoch_loss=tensor(0.0524, device='cuda:0') eval_ppl=tensor(1.0263, device='cuda:0') eval_epoch_loss=tensor(0.0260, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.41it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 15.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=32: train_ppl=tensor(1.0453, device='cuda:0') train_epoch_loss=tensor(0.0443, device='cuda:0') eval_ppl=tensor(1.0750, device='cuda:0') eval_epoch_loss=tensor(0.0723, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.41it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 15.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=33: train_ppl=tensor(1.0741, device='cuda:0') train_epoch_loss=tensor(0.0715, device='cuda:0') eval_ppl=tensor(1.0449, device='cuda:0') eval_epoch_loss=tensor(0.0440, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.41it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 15.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=34: train_ppl=tensor(1.0590, device='cuda:0') train_epoch_loss=tensor(0.0574, device='cuda:0') eval_ppl=tensor(1.1086, device='cuda:0') eval_epoch_loss=tensor(0.1031, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.40it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 15.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=35: train_ppl=tensor(1.0641, device='cuda:0') train_epoch_loss=tensor(0.0621, device='cuda:0') eval_ppl=tensor(1.0303, device='cuda:0') eval_epoch_loss=tensor(0.0299, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.37it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 15.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=36: train_ppl=tensor(1.0481, device='cuda:0') train_epoch_loss=tensor(0.0470, device='cuda:0') eval_ppl=tensor(1.0204, device='cuda:0') eval_epoch_loss=tensor(0.0202, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.36it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 15.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=37: train_ppl=tensor(1.0316, device='cuda:0') train_epoch_loss=tensor(0.0311, device='cuda:0') eval_ppl=tensor(1.0306, device='cuda:0') eval_epoch_loss=tensor(0.0301, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.36it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 15.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=38: train_ppl=tensor(1.0215, device='cuda:0') train_epoch_loss=tensor(0.0213, device='cuda:0') eval_ppl=tensor(1.0165, device='cuda:0') eval_epoch_loss=tensor(0.0164, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.36it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 15.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=39: train_ppl=tensor(1.0136, device='cuda:0') train_epoch_loss=tensor(0.0135, device='cuda:0') eval_ppl=tensor(1.0103, device='cuda:0') eval_epoch_loss=tensor(0.0103, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.34it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 15.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=40: train_ppl=tensor(1.0101, device='cuda:0') train_epoch_loss=tensor(0.0101, device='cuda:0') eval_ppl=tensor(1.0084, device='cuda:0') eval_epoch_loss=tensor(0.0084, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.32it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 15.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=41: train_ppl=tensor(1.0075, device='cuda:0') train_epoch_loss=tensor(0.0074, device='cuda:0') eval_ppl=tensor(1.0074, device='cuda:0') eval_epoch_loss=tensor(0.0074, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.30it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 15.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=42: train_ppl=tensor(1.0070, device='cuda:0') train_epoch_loss=tensor(0.0069, device='cuda:0') eval_ppl=tensor(1.0067, device='cuda:0') eval_epoch_loss=tensor(0.0067, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.34it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 15.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=43: train_ppl=tensor(1.0064, device='cuda:0') train_epoch_loss=tensor(0.0063, device='cuda:0') eval_ppl=tensor(1.0060, device='cuda:0') eval_epoch_loss=tensor(0.0060, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.29it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 15.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=44: train_ppl=tensor(1.0053, device='cuda:0') train_epoch_loss=tensor(0.0053, device='cuda:0') eval_ppl=tensor(1.0056, device='cuda:0') eval_epoch_loss=tensor(0.0055, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.31it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 15.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=45: train_ppl=tensor(1.0049, device='cuda:0') train_epoch_loss=tensor(0.0049, device='cuda:0') eval_ppl=tensor(1.0051, device='cuda:0') eval_epoch_loss=tensor(0.0051, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.29it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 15.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=46: train_ppl=tensor(1.0046, device='cuda:0') train_epoch_loss=tensor(0.0046, device='cuda:0') eval_ppl=tensor(1.0049, device='cuda:0') eval_epoch_loss=tensor(0.0049, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.27it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 15.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=47: train_ppl=tensor(1.0043, device='cuda:0') train_epoch_loss=tensor(0.0043, device='cuda:0') eval_ppl=tensor(1.0047, device='cuda:0') eval_epoch_loss=tensor(0.0047, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.27it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 15.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=48: train_ppl=tensor(1.0042, device='cuda:0') train_epoch_loss=tensor(0.0042, device='cuda:0') eval_ppl=tensor(1.0046, device='cuda:0') eval_epoch_loss=tensor(0.0046, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.27it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 15.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=49: train_ppl=tensor(1.0047, device='cuda:0') train_epoch_loss=tensor(0.0046, device='cuda:0') eval_ppl=tensor(1.0046, device='cuda:0') eval_epoch_loss=tensor(0.0046, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# training and evaluation\n",
    "model = model.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for step, batch in enumerate(tqdm(train_dataloader)):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        #         print(batch)\n",
    "        #         print(batch[\"input_ids\"].shape)\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.detach().float()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    model.eval()\n",
    "    eval_loss = 0\n",
    "    eval_preds = []\n",
    "    for step, batch in enumerate(tqdm(eval_dataloader)):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        eval_loss += loss.detach().float()\n",
    "        eval_preds.extend(\n",
    "            tokenizer.batch_decode(torch.argmax(outputs.logits, -1).detach().cpu().numpy(), skip_special_tokens=True)\n",
    "        )\n",
    "\n",
    "    eval_epoch_loss = eval_loss / len(eval_dataloader)\n",
    "    eval_ppl = torch.exp(eval_epoch_loss)\n",
    "    train_epoch_loss = total_loss / len(train_dataloader)\n",
    "    train_ppl = torch.exp(train_epoch_loss)\n",
    "    print(f\"{epoch=}: {train_ppl=} {train_epoch_loss=} {eval_ppl=} {eval_epoch_loss=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@TommyHilfiger Dramatic shopping exp. ordered 6 jeans same size (30/32) 2 fits / 2 too large / 2 too slim : same brand &gt; different sizing\n",
      "{'input_ids': tensor([[227985,   5484,    915,   2566, 226154, 126015,   5385,    259, 239364,\n",
      "           3396,  70823,   5853,     17,  57247,   1231, 191040,   5025,   7869,\n",
      "            375,   2324, 149349,     12,    415, 122321,    897,    415,  10136,\n",
      "          10021,    897,    415,  10136,   6497,    381,    915,   5025,  51950,\n",
      "          66869,   5955,    272,  20311,  77658,    915,    210]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "tensor([[227985,   5484,    915,   2566, 226154, 126015,   5385,    259, 239364,\n",
      "           3396,  70823,   5853,     17,  57247,   1231, 191040,   5025,   7869,\n",
      "            375,   2324, 149349,     12,    415, 122321,    897,    415,  10136,\n",
      "          10021,    897,    415,  10136,   6497,    381,    915,   5025,  51950,\n",
      "          66869,   5955,    272,  20311,  77658,    915,    210,  16449,   5952,\n",
      "              2,     31,     34,   5134,    189,   9028,    189,    939]],\n",
      "       device='cuda:0')\n",
      "['Tweet text : @TommyHilfiger Dramatic shopping exp. ordered 6 jeans same size (30/32) 2 fits / 2 too large / 2 too slim : same brand &gt; different sizing Label : complaint<?php\\n/**\\n *']\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "i = 33\n",
    "inputs = tokenizer(f'{text_column} : {dataset[\"test\"][i][\"Tweet text\"]} Label : ', return_tensors=\"pt\")\n",
    "print(dataset[\"test\"][i][\"Tweet text\"])\n",
    "print(inputs)\n",
    "\n",
    "with torch.no_grad():\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    outputs = model.generate(\n",
    "        input_ids=inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"], max_new_tokens=10, eos_token_id=3\n",
    "    )\n",
    "    print(outputs)\n",
    "    print(tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
