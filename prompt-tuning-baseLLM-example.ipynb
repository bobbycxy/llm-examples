{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Tuning Example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import libraries\n",
    "import creds\n",
    "import pandas as pd\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "model_name = 'bigscience/bloomz-560m'\n",
    "NUM_VIRTUAL_TOKENS = 10\n",
    "NUM_EPOCHS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "foundational_model = AutoModelForCausalLM.from_pretrained(model_name,\n",
    "                                                          trust_remote_code = True,\n",
    "                                                          token = creds.HUGGINGFACE_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a function that returns the outputs from the model we have received above, and inputs.\n",
    "def get_outputs(model, inputs, max_new_tokens = 100):\n",
    "    outputs = model.generate(\n",
    "        input_ids = inputs['input_ids'],\n",
    "        attention_mask = inputs['attention_mask'],\n",
    "        max_new_tokens = max_new_tokens,\n",
    "        repetition_penalty = 1.5, \n",
    "        early_stopping = True,\n",
    "        eos_token_id = tokenizer.eos_token_id,\n",
    "        num_beams = 6\n",
    "    )\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"I want you to act as a motivational coach. Don't be afraid to ask questions\"]\n"
     ]
    }
   ],
   "source": [
    "## get a smaple response from the above get_output and existing foundational models\n",
    "test_prompt = 'I want you to act as a motivational coach.'\n",
    "\n",
    "input_prompt = tokenizer(test_prompt, return_tensors = 'pt')\n",
    "foundational_outputs_prompt = get_outputs(foundational_model, input_prompt, max_new_tokens = 50)\n",
    "\n",
    "print(tokenizer.batch_decode(foundational_outputs_prompt, skip_special_tokens = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Give three tips for staying healthy.']\n"
     ]
    }
   ],
   "source": [
    "## get a smaple response from the above get_output and existing foundational models\n",
    "test_prompt = 'Give three tips for staying healthy.'\n",
    "\n",
    "input_prompt = tokenizer(test_prompt, return_tensors = 'pt')\n",
    "foundational_outputs_prompt = get_outputs(foundational_model, input_prompt, max_new_tokens = 50)\n",
    "\n",
    "print(tokenizer.batch_decode(foundational_outputs_prompt, skip_special_tokens = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What is the capital of France? Paris']\n"
     ]
    }
   ],
   "source": [
    "## get a smaple response from the above get_output and existing foundational models\n",
    "test_prompt = 'What is the capital of France?'\n",
    "\n",
    "input_prompt = tokenizer(test_prompt, return_tensors = 'pt')\n",
    "foundational_outputs_prompt = get_outputs(foundational_model, input_prompt, max_new_tokens = 50)\n",
    "\n",
    "print(tokenizer.batch_decode(foundational_outputs_prompt, skip_special_tokens = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What are the three primary colours? Red, Green and Blue']\n"
     ]
    }
   ],
   "source": [
    "## get a smaple response from the above get_output and existing foundational models\n",
    "test_prompt = 'What are the three primary colours?'\n",
    "\n",
    "input_prompt = tokenizer(test_prompt, return_tensors = 'pt')\n",
    "foundational_outputs_prompt = get_outputs(foundational_model, input_prompt, max_new_tokens = 50)\n",
    "\n",
    "print(tokenizer.batch_decode(foundational_outputs_prompt, skip_special_tokens = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What is an atom? a single particle of matter']\n"
     ]
    }
   ],
   "source": [
    "## get a smaple response from the above get_output and existing foundational models\n",
    "test_prompt = 'What is an atom?'\n",
    "\n",
    "input_prompt = tokenizer(test_prompt, return_tensors = 'pt')\n",
    "foundational_outputs_prompt = get_outputs(foundational_model, input_prompt, max_new_tokens = 50)\n",
    "\n",
    "print(tokenizer.batch_decode(foundational_outputs_prompt, skip_special_tokens = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 52002/52002 [00:02<00:00, 20792.92 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'input', 'output', 'text', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 52002\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datasets\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset_prompt = load_dataset(\"tatsu-lab/alpaca\", split=\"train\")\n",
    "\n",
    "#create the dataset to create prompts\n",
    "data_prompt = dataset_prompt.map(lambda samples:tokenizer(samples['text']), batched = True)\n",
    "train_sample_prompt = data_prompt.select(range(1000))\n",
    "\n",
    "display(data_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'input', 'output', 'text', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sample_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>text</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Give three tips for staying healthy.</td>\n",
       "      <td></td>\n",
       "      <td>1.Eat a balanced diet and make sure to include...</td>\n",
       "      <td>Below is an instruction that describes a task....</td>\n",
       "      <td>[111757, 632, 660, 54103, 861, 63808, 267, 201...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are the three primary colors?</td>\n",
       "      <td></td>\n",
       "      <td>The three primary colors are red, blue, and ye...</td>\n",
       "      <td>Below is an instruction that describes a task....</td>\n",
       "      <td>[111757, 632, 660, 54103, 861, 63808, 267, 201...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Describe the structure of an atom.</td>\n",
       "      <td></td>\n",
       "      <td>An atom is made up of a nucleus, which contain...</td>\n",
       "      <td>Below is an instruction that describes a task....</td>\n",
       "      <td>[111757, 632, 660, 54103, 861, 63808, 267, 201...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How can we reduce air pollution?</td>\n",
       "      <td></td>\n",
       "      <td>There are a number of ways to reduce air pollu...</td>\n",
       "      <td>Below is an instruction that describes a task....</td>\n",
       "      <td>[111757, 632, 660, 54103, 861, 63808, 267, 201...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Describe a time when you had to make a difficu...</td>\n",
       "      <td></td>\n",
       "      <td>I had to make a difficult decision when I was ...</td>\n",
       "      <td>Below is an instruction that describes a task....</td>\n",
       "      <td>[111757, 632, 660, 54103, 861, 63808, 267, 201...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Name the 6 most populous cities in China.</td>\n",
       "      <td></td>\n",
       "      <td>The six most populous cities in China are Shan...</td>\n",
       "      <td>Below is an instruction that describes a task....</td>\n",
       "      <td>[111757, 632, 660, 54103, 861, 63808, 267, 201...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Edit the following text to make it easier to read</td>\n",
       "      <td>In the 20th centuary,developments in the field...</td>\n",
       "      <td>In the 20th century, developments in the field...</td>\n",
       "      <td>Below is an instruction that describes a task,...</td>\n",
       "      <td>[111757, 632, 660, 54103, 861, 63808, 267, 201...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Determine the surface area of the following fi...</td>\n",
       "      <td>A cube with side length 2 cm</td>\n",
       "      <td>The surface area of the cube is 24 cm².</td>\n",
       "      <td>Below is an instruction that describes a task,...</td>\n",
       "      <td>[111757, 632, 660, 54103, 861, 63808, 267, 201...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Find the definition of the following financial...</td>\n",
       "      <td>Stock Split</td>\n",
       "      <td>A stock split is a corporate action in which a...</td>\n",
       "      <td>Below is an instruction that describes a task,...</td>\n",
       "      <td>[111757, 632, 660, 54103, 861, 63808, 267, 201...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Describe the flavor profile of the following t...</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>Japanese cuisine is characterized by its subtl...</td>\n",
       "      <td>Below is an instruction that describes a task,...</td>\n",
       "      <td>[111757, 632, 660, 54103, 861, 63808, 267, 201...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           instruction  \\\n",
       "0                 Give three tips for staying healthy.   \n",
       "1                   What are the three primary colors?   \n",
       "2                   Describe the structure of an atom.   \n",
       "3                     How can we reduce air pollution?   \n",
       "4    Describe a time when you had to make a difficu...   \n",
       "..                                                 ...   \n",
       "995          Name the 6 most populous cities in China.   \n",
       "996  Edit the following text to make it easier to read   \n",
       "997  Determine the surface area of the following fi...   \n",
       "998  Find the definition of the following financial...   \n",
       "999  Describe the flavor profile of the following t...   \n",
       "\n",
       "                                                 input  \\\n",
       "0                                                        \n",
       "1                                                        \n",
       "2                                                        \n",
       "3                                                        \n",
       "4                                                        \n",
       "..                                                 ...   \n",
       "995                                                      \n",
       "996  In the 20th centuary,developments in the field...   \n",
       "997                       A cube with side length 2 cm   \n",
       "998                                        Stock Split   \n",
       "999                                           Japanese   \n",
       "\n",
       "                                                output  \\\n",
       "0    1.Eat a balanced diet and make sure to include...   \n",
       "1    The three primary colors are red, blue, and ye...   \n",
       "2    An atom is made up of a nucleus, which contain...   \n",
       "3    There are a number of ways to reduce air pollu...   \n",
       "4    I had to make a difficult decision when I was ...   \n",
       "..                                                 ...   \n",
       "995  The six most populous cities in China are Shan...   \n",
       "996  In the 20th century, developments in the field...   \n",
       "997            The surface area of the cube is 24 cm².   \n",
       "998  A stock split is a corporate action in which a...   \n",
       "999  Japanese cuisine is characterized by its subtl...   \n",
       "\n",
       "                                                  text  \\\n",
       "0    Below is an instruction that describes a task....   \n",
       "1    Below is an instruction that describes a task....   \n",
       "2    Below is an instruction that describes a task....   \n",
       "3    Below is an instruction that describes a task....   \n",
       "4    Below is an instruction that describes a task....   \n",
       "..                                                 ...   \n",
       "995  Below is an instruction that describes a task....   \n",
       "996  Below is an instruction that describes a task,...   \n",
       "997  Below is an instruction that describes a task,...   \n",
       "998  Below is an instruction that describes a task,...   \n",
       "999  Below is an instruction that describes a task,...   \n",
       "\n",
       "                                             input_ids  \\\n",
       "0    [111757, 632, 660, 54103, 861, 63808, 267, 201...   \n",
       "1    [111757, 632, 660, 54103, 861, 63808, 267, 201...   \n",
       "2    [111757, 632, 660, 54103, 861, 63808, 267, 201...   \n",
       "3    [111757, 632, 660, 54103, 861, 63808, 267, 201...   \n",
       "4    [111757, 632, 660, 54103, 861, 63808, 267, 201...   \n",
       "..                                                 ...   \n",
       "995  [111757, 632, 660, 54103, 861, 63808, 267, 201...   \n",
       "996  [111757, 632, 660, 54103, 861, 63808, 267, 201...   \n",
       "997  [111757, 632, 660, 54103, 861, 63808, 267, 201...   \n",
       "998  [111757, 632, 660, 54103, 861, 63808, 267, 201...   \n",
       "999  [111757, 632, 660, 54103, 861, 63808, 267, 201...   \n",
       "\n",
       "                                        attention_mask  \n",
       "0    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "1    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "2    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "3    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "4    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "..                                                 ...  \n",
       "995  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "996  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "997  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "998  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "999  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "\n",
       "[1000 rows x 6 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(train_sample_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "## time to fine tune with Parameter Efficient Fine Tuning\n",
    "from peft import get_peft_model, PromptTuningConfig, TaskType, PromptTuningInit\n",
    "\n",
    "generator_config = PromptTuningConfig(\n",
    "    task_type = TaskType.CAUSAL_LM, # this makes the model generate text\n",
    "    prompt_tuning_init = PromptTuningInit.RANDOM, # initialise the virtual tokens with random numbers\n",
    "    num_virtual_tokens = NUM_VIRTUAL_TOKENS, # number of virtual tokens to add and train\n",
    "    tokenizer_name_or_path = model_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 10,240 || all params: 559,224,832 || trainable%: 0.0018311060979495275\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "peft_model_prompt = get_peft_model(foundational_model, generator_config)\n",
    "print(peft_model_prompt.print_trainable_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "## start to create the training configuration\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "def create_training_arguments(path, learning_rate = 0.0035, epochs = 6):\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir = path,\n",
    "        auto_find_batch_size = True,\n",
    "        learning_rate = learning_rate,\n",
    "        num_train_epochs = epochs\n",
    "    )\n",
    "\n",
    "    return training_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "## create directories to hold the model when they don't exist\n",
    "\n",
    "working_dir = './peft_baseLLM'\n",
    "\n",
    "## it is recommended to store the models seperately\n",
    "output_dir_prompt = os.path.join(working_dir, 'peft_outputs_prompt')\n",
    "output_dir_sentences = os.path.join(working_dir, 'peft_outputs_sentences')\n",
    "\n",
    "## create the directories if they don't exist\n",
    "if not os.path.exists(working_dir):\n",
    "    os.mkdir(working_dir)\n",
    "if not os.path.exists(output_dir_prompt):\n",
    "    os.mkdir(output_dir_prompt)\n",
    "if not os.path.exists(output_dir_sentences):\n",
    "    os.mkdir(output_dir_sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args_prompt = create_training_arguments(output_dir_prompt, 0.003, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, DataCollatorForLanguageModeling \n",
    "\n",
    "def create_trainer(model, training_args, train_dataset):\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args = training_args,\n",
    "        train_dataset = train_dataset,\n",
    "        data_collator = DataCollatorForLanguageModeling(tokenizer, mlm = False)\n",
    "    )\n",
    "\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='64' max='64' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [64/64 27:21, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=64, training_loss=3.493079662322998, metrics={'train_runtime': 1659.7604, 'train_samples_per_second': 1.205, 'train_steps_per_second': 0.039, 'total_flos': 909697514864640.0, 'train_loss': 3.493079662322998, 'epoch': 2.0})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## time to finetune the models\n",
    "trainer_prompt = create_trainer(peft_model_prompt, training_args_prompt, train_sample_prompt)\n",
    "trainer_prompt.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_prompt.model.save_pretrained(output_dir_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "\n",
    "loaded_model_prompt = PeftModel.from_pretrained(foundational_model,\n",
    "                                         output_dir_prompt,\n",
    "                                         #device_map='auto',\n",
    "                                         is_trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I want you to act as a motivational coach. By signing up for our newsletter, you agree to the Terms of Use']\n"
     ]
    }
   ],
   "source": [
    "## inference\n",
    "loaded_model_prompt_outputs = get_outputs(loaded_model_prompt, input_prompt)\n",
    "print(tokenizer.batch_decode(loaded_model_prompt_outputs, skip_special_tokens = True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Give three tips for staying healthy.']\n"
     ]
    }
   ],
   "source": [
    "## inference\n",
    "loaded_model_prompt_outputs = get_outputs(loaded_model_prompt, input_prompt)\n",
    "print(tokenizer.batch_decode(loaded_model_prompt_outputs, skip_special_tokens = True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What is the capital of France? Paris']\n"
     ]
    }
   ],
   "source": [
    "## inference\n",
    "loaded_model_prompt_outputs = get_outputs(loaded_model_prompt, input_prompt)\n",
    "print(tokenizer.batch_decode(loaded_model_prompt_outputs, skip_special_tokens = True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What are the three primary colours? Red, Green and Yellow']\n"
     ]
    }
   ],
   "source": [
    "## inference\n",
    "loaded_model_prompt_outputs = get_outputs(loaded_model_prompt, input_prompt)\n",
    "print(tokenizer.batch_decode(loaded_model_prompt_outputs, skip_special_tokens = True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What is an atom? a molecular entity']\n"
     ]
    }
   ],
   "source": [
    "## inference\n",
    "loaded_model_prompt_outputs = get_outputs(loaded_model_prompt, input_prompt)\n",
    "print(tokenizer.batch_decode(loaded_model_prompt_outputs, skip_special_tokens = True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['act', 'prompt', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 50\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## preparing the datasets\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset_prompt = 'fka/awesome-chatgpt-prompts'\n",
    "\n",
    "#create the dataset to create prompts\n",
    "data_prompt = load_dataset(dataset_prompt)\n",
    "data_prompt = data_prompt.map(lambda samples:tokenizer(samples['prompt']), batched = True)\n",
    "train_sample_prompt = data_prompt['train'].select(range(50))\n",
    "\n",
    "# train_sample_prompt = train_sample_prompt.remove_columns(['act','prompt'])\n",
    "\n",
    "display(train_sample_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['act', 'prompt', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 153\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>act</th>\n",
       "      <th>prompt</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linux Terminal</td>\n",
       "      <td>I want you to act as a linux terminal. I will ...</td>\n",
       "      <td>[2, 235285, 1938, 692, 577, 2027, 685, 476, 61...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>English Translator and Improver</td>\n",
       "      <td>I want you to act as an English translator, sp...</td>\n",
       "      <td>[2, 235285, 1938, 692, 577, 2027, 685, 671, 46...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>`position` Interviewer</td>\n",
       "      <td>I want you to act as an interviewer. I will be...</td>\n",
       "      <td>[2, 235285, 1938, 692, 577, 2027, 685, 671, 11...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JavaScript Console</td>\n",
       "      <td>I want you to act as a javascript console. I w...</td>\n",
       "      <td>[2, 235285, 1938, 692, 577, 2027, 685, 476, 77...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Excel Sheet</td>\n",
       "      <td>I want you to act as a text based excel. you'l...</td>\n",
       "      <td>[2, 235285, 1938, 692, 577, 2027, 685, 476, 27...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>English Pronunciation Helper</td>\n",
       "      <td>I want you to act as an English pronunciation ...</td>\n",
       "      <td>[2, 235285, 1938, 692, 577, 2027, 685, 671, 46...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Spoken English Teacher and Improver</td>\n",
       "      <td>I want you to act as a spoken English teacher ...</td>\n",
       "      <td>[2, 235285, 1938, 692, 577, 2027, 685, 476, 22...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Travel Guide</td>\n",
       "      <td>I want you to act as a travel guide. I will wr...</td>\n",
       "      <td>[2, 235285, 1938, 692, 577, 2027, 685, 476, 50...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Plagiarism Checker</td>\n",
       "      <td>I want you to act as a plagiarism checker. I w...</td>\n",
       "      <td>[2, 235285, 1938, 692, 577, 2027, 685, 476, 15...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Character from Movie/Book/Anything</td>\n",
       "      <td>I want you to act like {character} from {serie...</td>\n",
       "      <td>[2, 235285, 1938, 692, 577, 2027, 1154, 612, 2...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Advertiser</td>\n",
       "      <td>I want you to act as an advertiser. You will c...</td>\n",
       "      <td>[2, 235285, 1938, 692, 577, 2027, 685, 671, 17...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Storyteller</td>\n",
       "      <td>I want you to act as a storyteller. You will c...</td>\n",
       "      <td>[2, 235285, 1938, 692, 577, 2027, 685, 476, 18...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Football Commentator</td>\n",
       "      <td>I want you to act as a football commentator. I...</td>\n",
       "      <td>[2, 235285, 1938, 692, 577, 2027, 685, 476, 97...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Stand-up Comedian</td>\n",
       "      <td>I want you to act as a stand-up comedian. I wi...</td>\n",
       "      <td>[2, 235285, 1938, 692, 577, 2027, 685, 476, 22...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Motivational Coach</td>\n",
       "      <td>I want you to act as a motivational coach. I w...</td>\n",
       "      <td>[2, 235285, 1938, 692, 577, 2027, 685, 476, 75...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Composer</td>\n",
       "      <td>I want you to act as a composer. I will provid...</td>\n",
       "      <td>[2, 235285, 1938, 692, 577, 2027, 685, 476, 41...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Debater</td>\n",
       "      <td>I want you to act as a debater. I will provide...</td>\n",
       "      <td>[2, 235285, 1938, 692, 577, 2027, 685, 476, 78...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Debate Coach</td>\n",
       "      <td>I want you to act as a debate coach. I will pr...</td>\n",
       "      <td>[2, 235285, 1938, 692, 577, 2027, 685, 476, 17...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Screenwriter</td>\n",
       "      <td>I want you to act as a screenwriter. You will ...</td>\n",
       "      <td>[2, 235285, 1938, 692, 577, 2027, 685, 476, 19...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Novelist</td>\n",
       "      <td>I want you to act as a novelist. You will come...</td>\n",
       "      <td>[2, 235285, 1938, 692, 577, 2027, 685, 476, 93...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Movie Critic</td>\n",
       "      <td>I want you to act as a movie critic. You will ...</td>\n",
       "      <td>[2, 235285, 1938, 692, 577, 2027, 685, 476, 73...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Relationship Coach</td>\n",
       "      <td>I want you to act as a relationship coach. I w...</td>\n",
       "      <td>[2, 235285, 1938, 692, 577, 2027, 685, 476, 68...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Poet</td>\n",
       "      <td>I want you to act as a poet. You will create p...</td>\n",
       "      <td>[2, 235285, 1938, 692, 577, 2027, 685, 476, 12...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Rapper</td>\n",
       "      <td>I want you to act as a rapper. You will come u...</td>\n",
       "      <td>[2, 235285, 1938, 692, 577, 2027, 685, 476, 57...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Motivational Speaker</td>\n",
       "      <td>I want you to act as a motivational speaker. P...</td>\n",
       "      <td>[2, 235285, 1938, 692, 577, 2027, 685, 476, 75...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Philosophy Teacher</td>\n",
       "      <td>I want you to act as a philosophy teacher. I w...</td>\n",
       "      <td>[2, 235285, 1938, 692, 577, 2027, 685, 476, 19...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Philosopher</td>\n",
       "      <td>I want you to act as a philosopher. I will pro...</td>\n",
       "      <td>[2, 235285, 1938, 692, 577, 2027, 685, 476, 61...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Math Teacher</td>\n",
       "      <td>I want you to act as a math teacher. I will pr...</td>\n",
       "      <td>[2, 235285, 1938, 692, 577, 2027, 685, 476, 10...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>AI Writing Tutor</td>\n",
       "      <td>I want you to act as an AI writing tutor. I wi...</td>\n",
       "      <td>[2, 235285, 1938, 692, 577, 2027, 685, 671, 16...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>UX/UI Developer</td>\n",
       "      <td>I want you to act as a UX/UI developer. I will...</td>\n",
       "      <td>[2, 235285, 1938, 692, 577, 2027, 685, 476, 74...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Cyber Security Specialist</td>\n",
       "      <td>I want you to act as a cyber security speciali...</td>\n",
       "      <td>[2, 235285, 1938, 692, 577, 2027, 685, 476, 28...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Recruiter</td>\n",
       "      <td>I want you to act as a recruiter. I will provi...</td>\n",
       "      <td>[2, 235285, 1938, 692, 577, 2027, 685, 476, 16...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Life Coach</td>\n",
       "      <td>I want you to act as a life coach. I will prov...</td>\n",
       "      <td>[2, 235285, 1938, 692, 577, 2027, 685, 476, 19...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Etymologist</td>\n",
       "      <td>I want you to act as a etymologist. I will giv...</td>\n",
       "      <td>[2, 235285, 1938, 692, 577, 2027, 685, 476, 10...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Commentariat</td>\n",
       "      <td>I want you to act as a commentariat. I will pr...</td>\n",
       "      <td>[2, 235285, 1938, 692, 577, 2027, 685, 476, 49...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Magician</td>\n",
       "      <td>I want you to act as a magician. I will provid...</td>\n",
       "      <td>[2, 235285, 1938, 692, 577, 2027, 685, 476, 10...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Career Counselor</td>\n",
       "      <td>I want you to act as a career counselor. I wil...</td>\n",
       "      <td>[2, 235285, 1938, 692, 577, 2027, 685, 476, 74...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Pet Behaviorist</td>\n",
       "      <td>I want you to act as a pet behaviorist. I will...</td>\n",
       "      <td>[2, 235285, 1938, 692, 577, 2027, 685, 476, 73...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Personal Trainer</td>\n",
       "      <td>I want you to act as a personal trainer. I wil...</td>\n",
       "      <td>[2, 235285, 1938, 692, 577, 2027, 685, 476, 37...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Mental Health Adviser</td>\n",
       "      <td>I want you to act as a mental health adviser. ...</td>\n",
       "      <td>[2, 235285, 1938, 692, 577, 2027, 685, 476, 96...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Real Estate Agent</td>\n",
       "      <td>I want you to act as a real estate agent. I wi...</td>\n",
       "      <td>[2, 235285, 1938, 692, 577, 2027, 685, 476, 18...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Logistician</td>\n",
       "      <td>I want you to act as a logistician. I will pro...</td>\n",
       "      <td>[2, 235285, 1938, 692, 577, 2027, 685, 476, 38...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Dentist</td>\n",
       "      <td>I want you to act as a dentist. I will provide...</td>\n",
       "      <td>[2, 235285, 1938, 692, 577, 2027, 685, 476, 37...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Web Design Consultant</td>\n",
       "      <td>I want you to act as a web design consultant. ...</td>\n",
       "      <td>[2, 235285, 1938, 692, 577, 2027, 685, 476, 27...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>AI Assisted Doctor</td>\n",
       "      <td>I want you to act as an AI assisted doctor. I ...</td>\n",
       "      <td>[2, 235285, 1938, 692, 577, 2027, 685, 671, 16...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Doctor</td>\n",
       "      <td>I want you to act as a doctor and come up with...</td>\n",
       "      <td>[2, 235285, 1938, 692, 577, 2027, 685, 476, 93...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Accountant</td>\n",
       "      <td>I want you to act as an accountant and come up...</td>\n",
       "      <td>[2, 235285, 1938, 692, 577, 2027, 685, 671, 82...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Chef</td>\n",
       "      <td>I require someone who can suggest delicious re...</td>\n",
       "      <td>[2, 235285, 2817, 4630, 1064, 798, 9337, 15855...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Automobile Mechanic</td>\n",
       "      <td>Need somebody with expertise on automobiles re...</td>\n",
       "      <td>[2, 20004, 23059, 675, 21572, 611, 79002, 1031...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Artist Advisor</td>\n",
       "      <td>I want you to act as an artist advisor providi...</td>\n",
       "      <td>[2, 235285, 1938, 692, 577, 2027, 685, 671, 91...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    act  \\\n",
       "0                        Linux Terminal   \n",
       "1       English Translator and Improver   \n",
       "2                `position` Interviewer   \n",
       "3                    JavaScript Console   \n",
       "4                           Excel Sheet   \n",
       "5          English Pronunciation Helper   \n",
       "6   Spoken English Teacher and Improver   \n",
       "7                          Travel Guide   \n",
       "8                    Plagiarism Checker   \n",
       "9    Character from Movie/Book/Anything   \n",
       "10                           Advertiser   \n",
       "11                          Storyteller   \n",
       "12                 Football Commentator   \n",
       "13                    Stand-up Comedian   \n",
       "14                   Motivational Coach   \n",
       "15                             Composer   \n",
       "16                              Debater   \n",
       "17                         Debate Coach   \n",
       "18                         Screenwriter   \n",
       "19                             Novelist   \n",
       "20                         Movie Critic   \n",
       "21                   Relationship Coach   \n",
       "22                                 Poet   \n",
       "23                               Rapper   \n",
       "24                 Motivational Speaker   \n",
       "25                   Philosophy Teacher   \n",
       "26                          Philosopher   \n",
       "27                         Math Teacher   \n",
       "28                     AI Writing Tutor   \n",
       "29                      UX/UI Developer   \n",
       "30            Cyber Security Specialist   \n",
       "31                            Recruiter   \n",
       "32                           Life Coach   \n",
       "33                          Etymologist   \n",
       "34                         Commentariat   \n",
       "35                             Magician   \n",
       "36                     Career Counselor   \n",
       "37                      Pet Behaviorist   \n",
       "38                     Personal Trainer   \n",
       "39                Mental Health Adviser   \n",
       "40                    Real Estate Agent   \n",
       "41                          Logistician   \n",
       "42                              Dentist   \n",
       "43                Web Design Consultant   \n",
       "44                   AI Assisted Doctor   \n",
       "45                               Doctor   \n",
       "46                           Accountant   \n",
       "47                                 Chef   \n",
       "48                  Automobile Mechanic   \n",
       "49                       Artist Advisor   \n",
       "\n",
       "                                               prompt  \\\n",
       "0   I want you to act as a linux terminal. I will ...   \n",
       "1   I want you to act as an English translator, sp...   \n",
       "2   I want you to act as an interviewer. I will be...   \n",
       "3   I want you to act as a javascript console. I w...   \n",
       "4   I want you to act as a text based excel. you'l...   \n",
       "5   I want you to act as an English pronunciation ...   \n",
       "6   I want you to act as a spoken English teacher ...   \n",
       "7   I want you to act as a travel guide. I will wr...   \n",
       "8   I want you to act as a plagiarism checker. I w...   \n",
       "9   I want you to act like {character} from {serie...   \n",
       "10  I want you to act as an advertiser. You will c...   \n",
       "11  I want you to act as a storyteller. You will c...   \n",
       "12  I want you to act as a football commentator. I...   \n",
       "13  I want you to act as a stand-up comedian. I wi...   \n",
       "14  I want you to act as a motivational coach. I w...   \n",
       "15  I want you to act as a composer. I will provid...   \n",
       "16  I want you to act as a debater. I will provide...   \n",
       "17  I want you to act as a debate coach. I will pr...   \n",
       "18  I want you to act as a screenwriter. You will ...   \n",
       "19  I want you to act as a novelist. You will come...   \n",
       "20  I want you to act as a movie critic. You will ...   \n",
       "21  I want you to act as a relationship coach. I w...   \n",
       "22  I want you to act as a poet. You will create p...   \n",
       "23  I want you to act as a rapper. You will come u...   \n",
       "24  I want you to act as a motivational speaker. P...   \n",
       "25  I want you to act as a philosophy teacher. I w...   \n",
       "26  I want you to act as a philosopher. I will pro...   \n",
       "27  I want you to act as a math teacher. I will pr...   \n",
       "28  I want you to act as an AI writing tutor. I wi...   \n",
       "29  I want you to act as a UX/UI developer. I will...   \n",
       "30  I want you to act as a cyber security speciali...   \n",
       "31  I want you to act as a recruiter. I will provi...   \n",
       "32  I want you to act as a life coach. I will prov...   \n",
       "33  I want you to act as a etymologist. I will giv...   \n",
       "34  I want you to act as a commentariat. I will pr...   \n",
       "35  I want you to act as a magician. I will provid...   \n",
       "36  I want you to act as a career counselor. I wil...   \n",
       "37  I want you to act as a pet behaviorist. I will...   \n",
       "38  I want you to act as a personal trainer. I wil...   \n",
       "39  I want you to act as a mental health adviser. ...   \n",
       "40  I want you to act as a real estate agent. I wi...   \n",
       "41  I want you to act as a logistician. I will pro...   \n",
       "42  I want you to act as a dentist. I will provide...   \n",
       "43  I want you to act as a web design consultant. ...   \n",
       "44  I want you to act as an AI assisted doctor. I ...   \n",
       "45  I want you to act as a doctor and come up with...   \n",
       "46  I want you to act as an accountant and come up...   \n",
       "47  I require someone who can suggest delicious re...   \n",
       "48  Need somebody with expertise on automobiles re...   \n",
       "49  I want you to act as an artist advisor providi...   \n",
       "\n",
       "                                            input_ids  \\\n",
       "0   [2, 235285, 1938, 692, 577, 2027, 685, 476, 61...   \n",
       "1   [2, 235285, 1938, 692, 577, 2027, 685, 671, 46...   \n",
       "2   [2, 235285, 1938, 692, 577, 2027, 685, 671, 11...   \n",
       "3   [2, 235285, 1938, 692, 577, 2027, 685, 476, 77...   \n",
       "4   [2, 235285, 1938, 692, 577, 2027, 685, 476, 27...   \n",
       "5   [2, 235285, 1938, 692, 577, 2027, 685, 671, 46...   \n",
       "6   [2, 235285, 1938, 692, 577, 2027, 685, 476, 22...   \n",
       "7   [2, 235285, 1938, 692, 577, 2027, 685, 476, 50...   \n",
       "8   [2, 235285, 1938, 692, 577, 2027, 685, 476, 15...   \n",
       "9   [2, 235285, 1938, 692, 577, 2027, 1154, 612, 2...   \n",
       "10  [2, 235285, 1938, 692, 577, 2027, 685, 671, 17...   \n",
       "11  [2, 235285, 1938, 692, 577, 2027, 685, 476, 18...   \n",
       "12  [2, 235285, 1938, 692, 577, 2027, 685, 476, 97...   \n",
       "13  [2, 235285, 1938, 692, 577, 2027, 685, 476, 22...   \n",
       "14  [2, 235285, 1938, 692, 577, 2027, 685, 476, 75...   \n",
       "15  [2, 235285, 1938, 692, 577, 2027, 685, 476, 41...   \n",
       "16  [2, 235285, 1938, 692, 577, 2027, 685, 476, 78...   \n",
       "17  [2, 235285, 1938, 692, 577, 2027, 685, 476, 17...   \n",
       "18  [2, 235285, 1938, 692, 577, 2027, 685, 476, 19...   \n",
       "19  [2, 235285, 1938, 692, 577, 2027, 685, 476, 93...   \n",
       "20  [2, 235285, 1938, 692, 577, 2027, 685, 476, 73...   \n",
       "21  [2, 235285, 1938, 692, 577, 2027, 685, 476, 68...   \n",
       "22  [2, 235285, 1938, 692, 577, 2027, 685, 476, 12...   \n",
       "23  [2, 235285, 1938, 692, 577, 2027, 685, 476, 57...   \n",
       "24  [2, 235285, 1938, 692, 577, 2027, 685, 476, 75...   \n",
       "25  [2, 235285, 1938, 692, 577, 2027, 685, 476, 19...   \n",
       "26  [2, 235285, 1938, 692, 577, 2027, 685, 476, 61...   \n",
       "27  [2, 235285, 1938, 692, 577, 2027, 685, 476, 10...   \n",
       "28  [2, 235285, 1938, 692, 577, 2027, 685, 671, 16...   \n",
       "29  [2, 235285, 1938, 692, 577, 2027, 685, 476, 74...   \n",
       "30  [2, 235285, 1938, 692, 577, 2027, 685, 476, 28...   \n",
       "31  [2, 235285, 1938, 692, 577, 2027, 685, 476, 16...   \n",
       "32  [2, 235285, 1938, 692, 577, 2027, 685, 476, 19...   \n",
       "33  [2, 235285, 1938, 692, 577, 2027, 685, 476, 10...   \n",
       "34  [2, 235285, 1938, 692, 577, 2027, 685, 476, 49...   \n",
       "35  [2, 235285, 1938, 692, 577, 2027, 685, 476, 10...   \n",
       "36  [2, 235285, 1938, 692, 577, 2027, 685, 476, 74...   \n",
       "37  [2, 235285, 1938, 692, 577, 2027, 685, 476, 73...   \n",
       "38  [2, 235285, 1938, 692, 577, 2027, 685, 476, 37...   \n",
       "39  [2, 235285, 1938, 692, 577, 2027, 685, 476, 96...   \n",
       "40  [2, 235285, 1938, 692, 577, 2027, 685, 476, 18...   \n",
       "41  [2, 235285, 1938, 692, 577, 2027, 685, 476, 38...   \n",
       "42  [2, 235285, 1938, 692, 577, 2027, 685, 476, 37...   \n",
       "43  [2, 235285, 1938, 692, 577, 2027, 685, 476, 27...   \n",
       "44  [2, 235285, 1938, 692, 577, 2027, 685, 671, 16...   \n",
       "45  [2, 235285, 1938, 692, 577, 2027, 685, 476, 93...   \n",
       "46  [2, 235285, 1938, 692, 577, 2027, 685, 671, 82...   \n",
       "47  [2, 235285, 2817, 4630, 1064, 798, 9337, 15855...   \n",
       "48  [2, 20004, 23059, 675, 21572, 611, 79002, 1031...   \n",
       "49  [2, 235285, 1938, 692, 577, 2027, 685, 671, 91...   \n",
       "\n",
       "                                       attention_mask  \n",
       "0   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "1   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "2   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "3   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "4   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "5   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "6   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "7   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "8   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "9   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "10  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "11  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "12  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "13  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "14  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "15  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "16  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "17  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "18  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "19  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "20  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "21  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "22  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "23  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "24  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "25  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "26  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "27  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "28  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "29  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "30  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "31  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "32  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "33  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "34  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "35  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "36  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "37  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "38  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "39  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "40  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "41  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "42  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "43  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "44  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "45  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "46  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "47  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "48  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "49  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(train_sample_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask'],\n",
       "    num_rows: 25\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## prepare a second dataset \n",
    "dataset_sentences = load_dataset('Abirate/english_quotes')\n",
    "\n",
    "data_sentences = dataset_sentences.map(lambda samples:tokenizer(samples['quote']), batched = True)\n",
    "train_sample_sentences = data_sentences['train'].select(range(25))\n",
    "train_sample_sentences = train_sample_sentences.remove_columns(['quote','author','tags'])\n",
    "display(train_sample_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1502, 17143, 33218, 30, 39839, 4384, 632, 112...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1502, 10203, 239002, 15, 136192, 1049, 530, 2...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1502, 35417, 11217, 1306, 61759, 29, 368, 713...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1502, 6895, 7112, 38695, 15, 1427, 10512, 350...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[119533, 22630, 7160, 38695, 632, 3269, 267, 1...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[1502, 17143, 5268, 1152, 1306, 530, 5894, 359...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[1502, 124002, 83213, 59020, 3269, 20242, 8839...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[1502, 5448, 4472, 11700, 361, 19134, 3262, 11...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[1502, 5448, 3804, 20152, 14275, 15, 1965, 132...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[1502, 17143, 368, 7458, 861, 1152, 26338, 427...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[1502, 1411, 8603, 17848, 473, 1400, 6129, 225...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[1502, 7690, 1152, 4026, 427, 4472, 3595, 267,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[1502, 19908, 763, 51794, 109010, 87, 29497, 3...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[1502, 7690, 1152, 13485, 368, 40267, 15, 1152...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[1502, 214469, 35050, 2815, 632, 34181, 919, 3...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[119533, 24015, 632, 20886, 5268, 45406, 1728,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[1502, 171790, 168682, 2632, 120960, 30, 16915...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[1502, 4670, 20152, 632, 368, 40094, 388, 1173...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[1502, 81276, 661, 1320, 1152, 3121, 427, 6765...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[1502, 162312, 8071, 12562, 26150, 1800, 12851...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[1502, 97797, 23444, 15, 10440, 3276, 722, 267...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[1502, 7994, 14390, 368, 19134, 1701, 6482, 17...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[123916, 912, 1427, 149014, 861, 28077, 473, 5...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[1502, 4670, 722, 33218, 361, 267, 8876, 861, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[1502, 45308, 427, 368, 85105, 26696, 17, 1387...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            input_ids  \\\n",
       "0   [1502, 17143, 33218, 30, 39839, 4384, 632, 112...   \n",
       "1   [1502, 10203, 239002, 15, 136192, 1049, 530, 2...   \n",
       "2   [1502, 35417, 11217, 1306, 61759, 29, 368, 713...   \n",
       "3   [1502, 6895, 7112, 38695, 15, 1427, 10512, 350...   \n",
       "4   [119533, 22630, 7160, 38695, 632, 3269, 267, 1...   \n",
       "5   [1502, 17143, 5268, 1152, 1306, 530, 5894, 359...   \n",
       "6   [1502, 124002, 83213, 59020, 3269, 20242, 8839...   \n",
       "7   [1502, 5448, 4472, 11700, 361, 19134, 3262, 11...   \n",
       "8   [1502, 5448, 3804, 20152, 14275, 15, 1965, 132...   \n",
       "9   [1502, 17143, 368, 7458, 861, 1152, 26338, 427...   \n",
       "10  [1502, 1411, 8603, 17848, 473, 1400, 6129, 225...   \n",
       "11  [1502, 7690, 1152, 4026, 427, 4472, 3595, 267,...   \n",
       "12  [1502, 19908, 763, 51794, 109010, 87, 29497, 3...   \n",
       "13  [1502, 7690, 1152, 13485, 368, 40267, 15, 1152...   \n",
       "14  [1502, 214469, 35050, 2815, 632, 34181, 919, 3...   \n",
       "15  [119533, 24015, 632, 20886, 5268, 45406, 1728,...   \n",
       "16  [1502, 171790, 168682, 2632, 120960, 30, 16915...   \n",
       "17  [1502, 4670, 20152, 632, 368, 40094, 388, 1173...   \n",
       "18  [1502, 81276, 661, 1320, 1152, 3121, 427, 6765...   \n",
       "19  [1502, 162312, 8071, 12562, 26150, 1800, 12851...   \n",
       "20  [1502, 97797, 23444, 15, 10440, 3276, 722, 267...   \n",
       "21  [1502, 7994, 14390, 368, 19134, 1701, 6482, 17...   \n",
       "22  [123916, 912, 1427, 149014, 861, 28077, 473, 5...   \n",
       "23  [1502, 4670, 722, 33218, 361, 267, 8876, 861, ...   \n",
       "24  [1502, 45308, 427, 368, 85105, 26696, 17, 1387...   \n",
       "\n",
       "                                       attention_mask  \n",
       "0                   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  \n",
       "1   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "2   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "3                      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  \n",
       "4             [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  \n",
       "5   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "6   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "7   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "8   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "9          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  \n",
       "10  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "11  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "12  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "13      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  \n",
       "14  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "15      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  \n",
       "16         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  \n",
       "17  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "18  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "19  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "20                  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  \n",
       "21                  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  \n",
       "22  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "23  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "24  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(train_sample_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "## time to fine tune with Parameter Efficient Fine Tuning\n",
    "from peft import get_peft_model, PromptTuningConfig, TaskType, PromptTuningInit\n",
    "\n",
    "generator_config = PromptTuningConfig(\n",
    "    task_type = TaskType.CAUSAL_LM, # this makes the model generate text\n",
    "    prompt_tuning_init = PromptTuningInit.RANDOM, # initialise the virtual tokens with random numbers\n",
    "    num_virtual_tokens = NUM_VIRTUAL_TOKENS, # number of virtual tokens to add and train\n",
    "    tokenizer_name_or_path = model_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 10,240 || all params: 559,224,832 || trainable%: 0.0018311060979495275\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "peft_model_prompt = get_peft_model(foundational_model, generator_config)\n",
    "print(peft_model_prompt.print_trainable_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 10,240 || all params: 559,224,832 || trainable%: 0.0018311060979495275\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "peft_model_sentences = get_peft_model(foundational_model, generator_config)\n",
    "print(peft_model_sentences.print_trainable_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "## start to create the training configuration\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "def create_training_arguments(path, learning_rate = 0.0035, epochs = 6):\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir = path,\n",
    "        auto_find_batch_size = True,\n",
    "        learning_rate = learning_rate,\n",
    "        num_train_epochs = epochs\n",
    "    )\n",
    "\n",
    "    return training_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create directories to hold the model when they don't exist\n",
    "\n",
    "working_dir = './peft'\n",
    "\n",
    "## it is recommended to store the models seperately\n",
    "output_dir_prompt = os.path.join(working_dir, 'peft_outputs_prompt')\n",
    "output_dir_sentences = os.path.join(working_dir, 'peft_outputs_sentences')\n",
    "\n",
    "## create the directories if they don't exist\n",
    "if not os.path.exists(working_dir):\n",
    "    os.mkdir(working_dir)\n",
    "if not os.path.exists(output_dir_prompt):\n",
    "    os.mkdir(output_dir_prompt)\n",
    "if not os.path.exists(output_dir_sentences):\n",
    "    os.mkdir(output_dir_sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args_prompt = create_training_arguments(output_dir_prompt, 0.003, NUM_EPOCHS)\n",
    "training_args_sentences = create_training_arguments(output_dir_sentences, 0.0035, NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, DataCollatorForLanguageModeling \n",
    "\n",
    "def create_trainer(model, training_args, train_dataset):\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args = training_args,\n",
    "        train_dataset = train_dataset,\n",
    "        data_collator = DataCollatorForLanguageModeling(tokenizer, mlm = False)\n",
    "    )\n",
    "\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 01:30, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:41, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5, training_loss=4.071768188476563, metrics={'train_runtime': 51.5815, 'train_samples_per_second': 2.423, 'train_steps_per_second': 0.097, 'total_flos': 28795358208000.0, 'train_loss': 4.071768188476563, 'epoch': 5.0})"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## time to finetune the models\n",
    "trainer_prompt = create_trainer(peft_model_prompt, training_args_prompt, train_sample_prompt)\n",
    "trainer_prompt.train()\n",
    "\n",
    "trainer_sentences = create_trainer(peft_model_sentences, training_args_sentences, train_sample_sentences)\n",
    "trainer_sentences.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save the models\n",
    "trainer_prompt.model.save_pretrained(output_dir_prompt)\n",
    "trainer_sentences.model.save_pretrained(output_dir_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "\n",
    "loaded_model_prompt = PeftModel.from_pretrained(foundational_model,\n",
    "                                         output_dir_prompt,\n",
    "                                         #device_map='auto',\n",
    "                                         is_trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I want you to act as a motivational coach. Learn how to be a motivational coach']\n"
     ]
    }
   ],
   "source": [
    "## inference\n",
    "loaded_model_prompt_outputs = get_outputs(loaded_model_prompt, input_prompt)\n",
    "print(tokenizer.batch_decode(loaded_model_prompt_outputs, skip_special_tokens = True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I want you to act as a motivational coach. I want you to be a motivational coach.']\n"
     ]
    }
   ],
   "source": [
    "## inference\n",
    "loaded_model_prompt_outputs = get_outputs(loaded_model_prompt, input_prompt)\n",
    "print(tokenizer.batch_decode(loaded_model_prompt_outputs, skip_special_tokens = True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I want you to act as a motivational coach. I want you to be a motivational coach.']\n"
     ]
    }
   ],
   "source": [
    "## inference\n",
    "loaded_model_prompt_outputs = get_outputs(loaded_model_prompt, input_prompt)\n",
    "print(tokenizer.batch_decode(loaded_model_prompt_outputs, skip_special_tokens = True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model_sentences = PeftModel.from_pretrained(foundational_model,\n",
    "                                         output_dir_sentences,\n",
    "                                         #device_map='auto',\n",
    "                                         is_trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['There are two things that matter: income and wealth.']\n"
     ]
    }
   ],
   "source": [
    "## inference\n",
    "loaded_model_sentences_outputs = get_outputs(loaded_model_sentences, input_sentences)\n",
    "print(tokenizer.batch_decode(loaded_model_sentences_outputs, skip_special_tokens = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['There are two things that matter: time and money.']\n"
     ]
    }
   ],
   "source": [
    "## inference\n",
    "loaded_model_sentences_outputs = get_outputs(loaded_model_sentences, input_sentences)\n",
    "print(tokenizer.batch_decode(loaded_model_sentences_outputs, skip_special_tokens = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['There are two things that matter: time and money.']\n"
     ]
    }
   ],
   "source": [
    "## inference\n",
    "loaded_model_sentences_outputs = get_outputs(loaded_model_sentences, input_sentences)\n",
    "print(tokenizer.batch_decode(loaded_model_sentences_outputs, skip_special_tokens = True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
