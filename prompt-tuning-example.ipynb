{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Tuning Example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting peft\n",
      "  Downloading peft-0.8.2-py3-none-any.whl (183 kB)\n",
      "\u001b[K     |████████████████████████████████| 183 kB 23.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting transformers\n",
      "  Downloading transformers-4.38.1-py3-none-any.whl (8.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 8.5 MB 90.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting huggingface-hub>=0.17.0\n",
      "  Downloading huggingface_hub-0.20.3-py3-none-any.whl (330 kB)\n",
      "\u001b[K     |████████████████████████████████| 330 kB 136.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: psutil in ./env/lib/python3.8/site-packages (from peft) (5.9.8)\n",
      "Collecting numpy>=1.17\n",
      "  Using cached numpy-1.24.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "Collecting safetensors\n",
      "  Downloading safetensors-0.4.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 98.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting torch>=1.13.0\n",
      "  Downloading torch-2.2.1-cp38-cp38-manylinux1_x86_64.whl (755.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 755.5 MB 33 kB/s s eta 0:00:011     |████████████████████▉           | 491.7 MB 118.2 MB/s eta 0:00:03     |█████████████████████▎          | 501.8 MB 118.2 MB/s eta 0:00:03\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in ./env/lib/python3.8/site-packages (from peft) (23.2)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "\u001b[K     |████████████████████████████████| 78 kB 10.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyyaml\n",
      "  Downloading PyYAML-6.0.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (736 kB)\n",
      "\u001b[K     |████████████████████████████████| 736 kB 142.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting accelerate>=0.21.0\n",
      "  Downloading accelerate-0.27.2-py3-none-any.whl (279 kB)\n",
      "\u001b[K     |████████████████████████████████| 279 kB 121.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting regex!=2019.12.17\n",
      "  Downloading regex-2023.12.25-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (777 kB)\n",
      "\u001b[K     |████████████████████████████████| 777 kB 150.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting filelock\n",
      "  Downloading filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Collecting tokenizers<0.19,>=0.14\n",
      "  Downloading tokenizers-0.15.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.6 MB 116.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting requests\n",
      "  Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "\u001b[K     |████████████████████████████████| 62 kB 1.9 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in ./env/lib/python3.8/site-packages (from huggingface-hub>=0.17.0->peft) (4.10.0)\n",
      "Collecting fsspec>=2023.5.0\n",
      "  Downloading fsspec-2024.2.0-py3-none-any.whl (170 kB)\n",
      "\u001b[K     |████████████████████████████████| 170 kB 136.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 196.0 MB 98.4 MB/s eta 0:00:011     |█████████████████▏              | 105.0 MB 106.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.1 MB 105.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 410.6 MB 111.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 731.7 MB 53 kB/s /s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 23.7 MB 148.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 56.5 MB 93.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting networkx\n",
      "  Downloading networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 139.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[K     |████████████████████████████████| 823 kB 130.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sympy\n",
      "  Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.7 MB 118.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 121.6 MB 110.6 MB/s eta 0:00:01     |████████████████████████████▋   | 108.6 MB 135.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting triton==2.2.0; platform_system == \"Linux\" and platform_machine == \"x86_64\" and python_version < \"3.12\"\n",
      "  Downloading triton-2.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 167.9 MB 117.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 124.2 MB 772 kB/s eta 0:00:011\n",
      "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 166.0 MB 114.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[K     |████████████████████████████████| 99 kB 18.6 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting jinja2\n",
      "  Downloading Jinja2-3.1.3-py3-none-any.whl (133 kB)\n",
      "\u001b[K     |████████████████████████████████| 133 kB 108.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting certifi>=2017.4.17\n",
      "  Downloading certifi-2024.2.2-py3-none-any.whl (163 kB)\n",
      "\u001b[K     |████████████████████████████████| 163 kB 155.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting idna<4,>=2.5\n",
      "  Downloading idna-3.6-py3-none-any.whl (61 kB)\n",
      "\u001b[K     |████████████████████████████████| 61 kB 305 kB/s s eta 0:00:01\n",
      "\u001b[?25hCollecting charset-normalizer<4,>=2\n",
      "  Downloading charset_normalizer-3.3.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
      "\u001b[K     |████████████████████████████████| 141 kB 94.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting urllib3<3,>=1.21.1\n",
      "  Downloading urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
      "\u001b[K     |████████████████████████████████| 121 kB 85.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-nvjitlink-cu12\n",
      "  Downloading nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl (20.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 20.5 MB 152.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting mpmath>=0.19\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[K     |████████████████████████████████| 536 kB 116.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting MarkupSafe>=2.0\n",
      "  Downloading MarkupSafe-2.1.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26 kB)\n",
      "Installing collected packages: pyyaml, regex, filelock, tqdm, certifi, idna, charset-normalizer, urllib3, requests, fsspec, huggingface-hub, tokenizers, numpy, safetensors, transformers, nvidia-nvjitlink-cu12, nvidia-cusparse-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cudnn-cu12, nvidia-cuda-nvrtc-cu12, nvidia-curand-cu12, networkx, nvidia-cuda-runtime-cu12, mpmath, sympy, nvidia-cufft-cu12, triton, nvidia-cusolver-cu12, nvidia-nccl-cu12, nvidia-nvtx-cu12, MarkupSafe, jinja2, torch, accelerate, peft\n",
      "Successfully installed MarkupSafe-2.1.5 accelerate-0.27.2 certifi-2024.2.2 charset-normalizer-3.3.2 filelock-3.13.1 fsspec-2024.2.0 huggingface-hub-0.20.3 idna-3.6 jinja2-3.1.3 mpmath-1.3.0 networkx-3.1 numpy-1.24.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.3.101 nvidia-nvtx-cu12-12.1.105 peft-0.8.2 pyyaml-6.0.1 regex-2023.12.25 requests-2.31.0 safetensors-0.4.2 sympy-1.12 tokenizers-0.15.2 torch-2.2.1 tqdm-4.66.2 transformers-4.38.1 triton-2.2.0 urllib3-2.2.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Using cached datasets-2.17.1-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: filelock in ./env/lib/python3.8/site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in ./env/lib/python3.8/site-packages (from datasets) (1.24.4)\n",
      "Collecting pyarrow>=12.0.0 (from datasets)\n",
      "  Using cached pyarrow-15.0.0-cp38-cp38-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting pyarrow-hotfix (from datasets)\n",
      "  Using cached pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pandas (from datasets)\n",
      "  Downloading pandas-2.0.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Requirement already satisfied: requests>=2.19.0 in ./env/lib/python3.8/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in ./env/lib/python3.8/site-packages (from datasets) (4.66.2)\n",
      "Collecting xxhash (from datasets)\n",
      "  Using cached xxhash-3.4.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from datasets)\n",
      "  Using cached multiprocess-0.70.16-py38-none-any.whl.metadata (7.1 kB)\n",
      "Collecting fsspec<=2023.10.0,>=2023.1.0 (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets)\n",
      "  Using cached fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting aiohttp (from datasets)\n",
      "  Using cached aiohttp-3.9.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in ./env/lib/python3.8/site-packages (from datasets) (0.20.3)\n",
      "Requirement already satisfied: packaging in ./env/lib/python3.8/site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./env/lib/python3.8/site-packages (from datasets) (6.0.1)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp->datasets)\n",
      "  Using cached attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Using cached frozenlist-1.4.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Using cached multidict-6.0.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets)\n",
      "  Using cached yarl-1.9.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
      "Collecting async-timeout<5.0,>=4.0 (from aiohttp->datasets)\n",
      "  Using cached async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./env/lib/python3.8/site-packages (from huggingface-hub>=0.19.4->datasets) (4.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./env/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./env/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./env/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./env/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./env/lib/python3.8/site-packages (from pandas->datasets) (2.8.2)\n",
      "Collecting pytz>=2020.1 (from pandas->datasets)\n",
      "  Downloading pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.1 (from pandas->datasets)\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in ./env/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Using cached datasets-2.17.1-py3-none-any.whl (536 kB)\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Using cached fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
      "Using cached aiohttp-3.9.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "Using cached pyarrow-15.0.0-cp38-cp38-manylinux_2_28_x86_64.whl (38.4 MB)\n",
      "Using cached multiprocess-0.70.16-py38-none-any.whl (132 kB)\n",
      "Downloading pandas-2.0.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m84.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Using cached xxhash-3.4.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Using cached attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "Using cached frozenlist-1.4.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (240 kB)\n",
      "Using cached multidict-6.0.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
      "Downloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m505.5/505.5 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.4/345.4 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached yarl-1.9.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (308 kB)\n",
      "Installing collected packages: pytz, xxhash, tzdata, pyarrow-hotfix, pyarrow, multidict, fsspec, frozenlist, dill, attrs, async-timeout, yarl, pandas, multiprocess, aiosignal, aiohttp, datasets\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.2.0\n",
      "    Uninstalling fsspec-2024.2.0:\n",
      "      Successfully uninstalled fsspec-2024.2.0\n",
      "Successfully installed aiohttp-3.9.3 aiosignal-1.3.1 async-timeout-4.0.3 attrs-23.2.0 datasets-2.17.1 dill-0.3.8 frozenlist-1.4.1 fsspec-2023.10.0 multidict-6.0.5 multiprocess-0.70.16 pandas-2.0.3 pyarrow-15.0.0 pyarrow-hotfix-0.6 pytz-2024.1 tzdata-2024.1 xxhash-3.4.1 yarl-1.9.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in ./env/lib/python3.8/site-packages (4.38.1)\n",
      "Requirement already satisfied: filelock in ./env/lib/python3.8/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in ./env/lib/python3.8/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: numpy>=1.17 in ./env/lib/python3.8/site-packages (from transformers) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./env/lib/python3.8/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./env/lib/python3.8/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./env/lib/python3.8/site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in ./env/lib/python3.8/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in ./env/lib/python3.8/site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./env/lib/python3.8/site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./env/lib/python3.8/site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./env/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./env/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./env/lib/python3.8/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./env/lib/python3.8/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./env/lib/python3.8/site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./env/lib/python3.8/site-packages (from requests->transformers) (2024.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import libraries\n",
    "import pandas as pd\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "model_name = 'bigscience/bloomz-560m'\n",
    "NUM_VIRTUAL_TOKENS = 4\n",
    "NUM_EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer_config.json: 100%|██████████| 222/222 [00:00<00:00, 44.8kB/s]\n",
      "tokenizer.json: 100%|██████████| 14.5M/14.5M [00:00<00:00, 97.4MB/s]\n",
      "special_tokens_map.json: 100%|██████████| 85.0/85.0 [00:00<00:00, 80.7kB/s]\n",
      "config.json: 100%|██████████| 715/715 [00:00<00:00, 601kB/s]\n",
      "model.safetensors: 100%|██████████| 1.12G/1.12G [00:09<00:00, 116MB/s]\n"
     ]
    }
   ],
   "source": [
    "## load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "foundational_model = AutoModelForCausalLM.from_pretrained(model_name,\n",
    "                                                          trust_remote_code = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a function that returns the outputs from the model we have received above, and inputs.\n",
    "def get_outputs(model, inputs, max_new_tokens = 100):\n",
    "    outputs = model.generate(\n",
    "        input_ids = inputs['input_ids'],\n",
    "        attention_mask = inputs['attention_mask'],\n",
    "        max_new_tokens = max_new_tokens,\n",
    "        repetition_penalty = 1.5, \n",
    "        early_stopping = True,\n",
    "        eos_token_id = tokenizer.eos_token_id,\n",
    "        num_beams = 6\n",
    "    )\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"I want you to act as a motivational coach. Don't be afraid to ask questions\"]\n"
     ]
    }
   ],
   "source": [
    "## get a smaple response from the above get_output and existing foundational models\n",
    "test_prompt = 'I want you to act as a motivational coach.'\n",
    "\n",
    "input_prompt = tokenizer(test_prompt, return_tensors = 'pt')\n",
    "foundational_outputs_prompt = get_outputs(foundational_model, input_prompt, max_new_tokens = 50)\n",
    "\n",
    "print(tokenizer.batch_decode(foundational_outputs_prompt, skip_special_tokens = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['There are two things that matter: quality and quantity. quality matters more than quantity.']\n"
     ]
    }
   ],
   "source": [
    "## get a smaple response from the above get_output and existing foundational models\n",
    "test_sentence = 'There are two things that matter:'\n",
    "\n",
    "input_sentences = tokenizer(test_sentence, return_tensors = 'pt')\n",
    "foundational_outputs_sentence = get_outputs(foundational_model, input_sentences, max_new_tokens = 50)\n",
    "\n",
    "print(tokenizer.batch_decode(foundational_outputs_sentence, skip_special_tokens = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 50\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## preparing the datasets\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset_prompt = 'fka/awesome-chatgpt-prompts'\n",
    "\n",
    "#create the dataset to create prompts\n",
    "data_prompt = load_dataset(dataset_prompt)\n",
    "data_prompt = data_prompt.map(lambda samples:tokenizer(samples['prompt']), batched = True)\n",
    "train_sample_prompt = data_prompt['train'].select(range(50))\n",
    "\n",
    "train_sample_prompt = train_sample_prompt.remove_columns(['act'])\n",
    "\n",
    "display(train_sample_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I want you to act as a linux terminal. I will ...</td>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 267, 104105, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I want you to act as an English translator, sp...</td>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 660, 7165, 24...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I want you to act as an interviewer. I will be...</td>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 660, 33322, 2...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I want you to act as a javascript console. I w...</td>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 267, 49760, 1...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I want you to act as a text based excel. you'l...</td>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 267, 5484, 11...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I want you to act as an English pronunciation ...</td>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 660, 7165, 14...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I want you to act as a spoken English teacher ...</td>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 267, 93949, 7...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I want you to act as a travel guide. I will wr...</td>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 267, 25008, 2...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I want you to act as a plagiarism checker. I w...</td>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 267, 159667, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I want you to act like {character} from {serie...</td>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 3269, 731, 84491, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>I want you to act as an advertiser. You will c...</td>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 660, 32482, 6...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>I want you to act as a storyteller. You will c...</td>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 267, 26143, 8...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>I want you to act as a football commentator. I...</td>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 267, 33929, 1...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>I want you to act as a stand-up comedian. I wi...</td>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 267, 8947, 22...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>I want you to act as a motivational coach. I w...</td>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 267, 22675, 3...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>I want you to act as a composer. I will provid...</td>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 267, 123873, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>I want you to act as a debater. I will provide...</td>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 267, 180898, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>I want you to act as a debate coach. I will pr...</td>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 267, 16860, 6...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>I want you to act as a screenwriter. You will ...</td>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 267, 19901, 8...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>I want you to act as a novelist. You will come...</td>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 267, 22422, 6...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>I want you to act as a movie critic. You will ...</td>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 267, 51651, 2...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>I want you to act as a relationship coach. I w...</td>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 267, 23556, 6...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>I want you to act as a poet. You will create p...</td>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 267, 57046, 1...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>I want you to act as a rapper. You will come u...</td>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 267, 213382, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>I want you to act as a motivational speaker. P...</td>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 267, 22675, 3...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>I want you to act as a philosophy teacher. I w...</td>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 267, 97350, 5...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>I want you to act as a philosopher. I will pro...</td>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 267, 213939, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>I want you to act as a math teacher. I will pr...</td>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 267, 23213, 5...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>I want you to act as an AI writing tutor. I wi...</td>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 660, 75299, 2...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>I want you to act as a UX/UI developer. I will...</td>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 267, 764, 168...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>I want you to act as a cyber security speciali...</td>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 267, 102127, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>I want you to act as a recruiter. I will provi...</td>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 267, 31192, 8...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>I want you to act as a life coach. I will prov...</td>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 267, 10440, 6...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>I want you to act as a etymologist. I will giv...</td>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 267, 173675, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>I want you to act as a commentariat. I will pr...</td>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 267, 11051, 1...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>I want you to act as a magician. I will provid...</td>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 267, 5630, 53...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>I want you to act as a career counselor. I wil...</td>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 267, 59436, 1...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>I want you to act as a pet behaviorist. I will...</td>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 267, 4620, 26...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>I want you to act as a personal trainer. I wil...</td>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 267, 9022, 19...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>I want you to act as a mental health adviser. ...</td>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 267, 22191, 1...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>I want you to act as a real estate agent. I wi...</td>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 267, 2910, 10...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>I want you to act as a logistician. I will pro...</td>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 267, 230674, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>I want you to act as a dentist. I will provide...</td>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 267, 48488, 6...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>I want you to act as a web design consultant. ...</td>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 267, 6848, 94...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>I want you to act as an AI assisted doctor. I ...</td>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 660, 75299, 1...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>I want you to act as a doctor and come up with...</td>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 267, 27738, 5...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>I want you to act as an accountant and come up...</td>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 660, 13538, 4...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>I require someone who can suggest delicious re...</td>\n",
       "      <td>[44, 12865, 20886, 5268, 1400, 12580, 192316, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Need somebody with expertise on automobiles re...</td>\n",
       "      <td>[95694, 57624, 1002, 116270, 664, 215903, 3669...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>I want you to act as an artist advisor providi...</td>\n",
       "      <td>[44, 4026, 1152, 427, 1769, 661, 660, 53292, 2...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               prompt  ...                                     attention_mask\n",
       "0   I want you to act as a linux terminal. I will ...  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "1   I want you to act as an English translator, sp...  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "2   I want you to act as an interviewer. I will be...  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "3   I want you to act as a javascript console. I w...  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "4   I want you to act as a text based excel. you'l...  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "5   I want you to act as an English pronunciation ...  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "6   I want you to act as a spoken English teacher ...  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "7   I want you to act as a travel guide. I will wr...  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "8   I want you to act as a plagiarism checker. I w...  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "9   I want you to act like {character} from {serie...  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "10  I want you to act as an advertiser. You will c...  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "11  I want you to act as a storyteller. You will c...  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "12  I want you to act as a football commentator. I...  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "13  I want you to act as a stand-up comedian. I wi...  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "14  I want you to act as a motivational coach. I w...  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "15  I want you to act as a composer. I will provid...  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "16  I want you to act as a debater. I will provide...  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "17  I want you to act as a debate coach. I will pr...  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "18  I want you to act as a screenwriter. You will ...  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "19  I want you to act as a novelist. You will come...  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "20  I want you to act as a movie critic. You will ...  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "21  I want you to act as a relationship coach. I w...  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "22  I want you to act as a poet. You will create p...  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "23  I want you to act as a rapper. You will come u...  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "24  I want you to act as a motivational speaker. P...  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "25  I want you to act as a philosophy teacher. I w...  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "26  I want you to act as a philosopher. I will pro...  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "27  I want you to act as a math teacher. I will pr...  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "28  I want you to act as an AI writing tutor. I wi...  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "29  I want you to act as a UX/UI developer. I will...  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "30  I want you to act as a cyber security speciali...  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "31  I want you to act as a recruiter. I will provi...  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "32  I want you to act as a life coach. I will prov...  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "33  I want you to act as a etymologist. I will giv...  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "34  I want you to act as a commentariat. I will pr...  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "35  I want you to act as a magician. I will provid...  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "36  I want you to act as a career counselor. I wil...  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "37  I want you to act as a pet behaviorist. I will...  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "38  I want you to act as a personal trainer. I wil...  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "39  I want you to act as a mental health adviser. ...  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "40  I want you to act as a real estate agent. I wi...  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "41  I want you to act as a logistician. I will pro...  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "42  I want you to act as a dentist. I will provide...  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "43  I want you to act as a web design consultant. ...  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "44  I want you to act as an AI assisted doctor. I ...  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "45  I want you to act as a doctor and come up with...  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "46  I want you to act as an accountant and come up...  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "47  I require someone who can suggest delicious re...  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "48  Need somebody with expertise on automobiles re...  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "49  I want you to act as an artist advisor providi...  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "\n",
       "[50 rows x 3 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(train_sample_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['quote', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 25\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## prepare a second dataset \n",
    "dataset_sentences = load_dataset('Abirate/english_quotes')\n",
    "\n",
    "data_sentences = dataset_sentences.map(lambda samples:tokenizer(samples['quote']), batched = True)\n",
    "train_sample_sentences = data_sentences['train'].select(range(25))\n",
    "train_sample_sentences = train_sample_sentences.remove_columns(['author','tags'])\n",
    "display(train_sample_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quote</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>“Be yourself; everyone else is already taken.”</td>\n",
       "      <td>[1502, 17143, 33218, 30, 39839, 4384, 632, 112...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>“I'm selfish, impatient and a little insecure....</td>\n",
       "      <td>[1502, 10203, 239002, 15, 136192, 1049, 530, 2...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>“Two things are infinite: the universe and hum...</td>\n",
       "      <td>[1502, 35417, 11217, 1306, 61759, 29, 368, 713...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>“So many books, so little time.”</td>\n",
       "      <td>[1502, 6895, 7112, 38695, 15, 1427, 10512, 350...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>“A room without books is like a body without a...</td>\n",
       "      <td>[119533, 22630, 7160, 38695, 632, 3269, 267, 1...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>“Be who you are and say what you feel, because...</td>\n",
       "      <td>[1502, 17143, 5268, 1152, 1306, 530, 5894, 359...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>“You've gotta dance like there's nobody watchi...</td>\n",
       "      <td>[1502, 124002, 83213, 59020, 3269, 20242, 8839...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>“You know you're in love when you can't fall a...</td>\n",
       "      <td>[1502, 5448, 4472, 11700, 361, 19134, 3262, 11...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>“You only live once, but if you do it right, o...</td>\n",
       "      <td>[1502, 5448, 3804, 20152, 14275, 15, 1965, 132...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>“Be the change that you wish to see in the wor...</td>\n",
       "      <td>[1502, 17143, 368, 7458, 861, 1152, 26338, 427...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>“In three words I can sum up everything I've l...</td>\n",
       "      <td>[1502, 1411, 8603, 17848, 473, 1400, 6129, 225...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>“If you want to know what a man's like, take a...</td>\n",
       "      <td>[1502, 7690, 1152, 4026, 427, 4472, 3595, 267,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>“Donâ€™t walk in front of meâ€¦ I may not foll...</td>\n",
       "      <td>[1502, 19908, 763, 51794, 109010, 87, 29497, 3...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>“If you tell the truth, you don't have to reme...</td>\n",
       "      <td>[1502, 7690, 1152, 13485, 368, 40267, 15, 1152...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>“Friendship ... is born at the moment when one...</td>\n",
       "      <td>[1502, 214469, 35050, 2815, 632, 34181, 919, 3...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>“A friend is someone who knows all about you a...</td>\n",
       "      <td>[119533, 24015, 632, 20886, 5268, 45406, 1728,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>“Always forgive your enemies; nothing annoys t...</td>\n",
       "      <td>[1502, 171790, 168682, 2632, 120960, 30, 16915...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>“To live is the rarest thing in the world. Mos...</td>\n",
       "      <td>[1502, 4670, 20152, 632, 368, 40094, 388, 1173...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>“Live as if you were to die tomorrow. Learn as...</td>\n",
       "      <td>[1502, 81276, 661, 1320, 1152, 3121, 427, 6765...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>“Darkness cannot drive out darkness: only ligh...</td>\n",
       "      <td>[1502, 162312, 8071, 12562, 26150, 1800, 12851...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>“Without music, life would be a mistake.”</td>\n",
       "      <td>[1502, 97797, 23444, 15, 10440, 3276, 722, 267...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>“We accept the love we think we deserve.”</td>\n",
       "      <td>[1502, 7994, 14390, 368, 19134, 1701, 6482, 17...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>“I am so clever that sometimes I don't underst...</td>\n",
       "      <td>[123916, 912, 1427, 149014, 861, 28077, 473, 5...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>“To be yourself in a world that is constantly ...</td>\n",
       "      <td>[1502, 4670, 722, 33218, 361, 267, 8876, 861, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>“Here's to the crazy ones. The misfits. The re...</td>\n",
       "      <td>[1502, 45308, 427, 368, 85105, 26696, 17, 1387...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                quote  ...                                     attention_mask\n",
       "0      “Be yourself; everyone else is already taken.”  ...                  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
       "1   “I'm selfish, impatient and a little insecure....  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "2   “Two things are infinite: the universe and hum...  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "3                    “So many books, so little time.”  ...                     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
       "4   “A room without books is like a body without a...  ...            [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
       "5   “Be who you are and say what you feel, because...  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "6   “You've gotta dance like there's nobody watchi...  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "7   “You know you're in love when you can't fall a...  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "8   “You only live once, but if you do it right, o...  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "9   “Be the change that you wish to see in the wor...  ...         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
       "10  “In three words I can sum up everything I've l...  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "11  “If you want to know what a man's like, take a...  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "12  “Donâ€™t walk in front of meâ€¦ I may not foll...  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "13  “If you tell the truth, you don't have to reme...  ...      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
       "14  “Friendship ... is born at the moment when one...  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "15  “A friend is someone who knows all about you a...  ...      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
       "16  “Always forgive your enemies; nothing annoys t...  ...         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
       "17  “To live is the rarest thing in the world. Mos...  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "18  “Live as if you were to die tomorrow. Learn as...  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "19  “Darkness cannot drive out darkness: only ligh...  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "20          “Without music, life would be a mistake.”  ...                  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
       "21          “We accept the love we think we deserve.”  ...                  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
       "22  “I am so clever that sometimes I don't underst...  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "23  “To be yourself in a world that is constantly ...  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "24  “Here's to the crazy ones. The misfits. The re...  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "\n",
       "[25 rows x 3 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(train_sample_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "## time to fine tune with Parameter Efficient Fine Tuning\n",
    "from peft import get_peft_model, PromptTuningConfig, TaskType, PromptTuningInit\n",
    "\n",
    "generator_config = PromptTuningConfig(\n",
    "    task_type = TaskType.CAUSAL_LM, # this makes the model generate text\n",
    "    prompt_tuning_init = PromptTuningInit.RANDOM, # initialise the virtual tokens with random numbers\n",
    "    num_virtual_tokens = NUM_VIRTUAL_TOKENS, # number of virtual tokens to add and train\n",
    "    tokenizer_name_or_path = model_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 4,096 || all params: 559,218,688 || trainable%: 0.0007324504863471229\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "peft_model_prompt = get_peft_model(foundational_model, generator_config)\n",
    "print(peft_model_prompt.print_trainable_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 4,096 || all params: 559,218,688 || trainable%: 0.0007324504863471229\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "peft_model_sentences = get_peft_model(foundational_model, generator_config)\n",
    "print(peft_model_sentences.print_trainable_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "## start to create the training configuration\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "def create_training_arguments(path, learning_rate = 0.0035, epochs = 6):\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir = path,\n",
    "        auto_find_batch_size = True,\n",
    "        learning_rate = learning_rate,\n",
    "        num_train_epochs = epochs\n",
    "    )\n",
    "\n",
    "    return training_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create directories to hold the model when they don't exist\n",
    "\n",
    "working_dir = './peft'\n",
    "\n",
    "## it is recommended to store the models seperately\n",
    "output_dir_prompt = os.path.join(working_dir, 'peft_outputs_prompt')\n",
    "output_dir_sentences = os.path.join(working_dir, 'peft_outputs_sentences')\n",
    "\n",
    "## create the directories if they don't exist\n",
    "if not os.path.exists(working_dir):\n",
    "    os.mkdir(working_dir)\n",
    "if not os.path.exists(output_dir_prompt):\n",
    "    os.mkdir(output_dir_prompt)\n",
    "if not os.path.exists(output_dir_sentences):\n",
    "    os.mkdir(output_dir_sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args_prompt = create_training_arguments(output_dir_prompt, 0.003, NUM_EPOCHS)\n",
    "training_args_sentences = create_training_arguments(output_dir_sentences, 0.0035, NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, DataCollatorForLanguageModeling \n",
    "\n",
    "def create_trainer(model, training_args, train_dataset):\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args = training_args,\n",
    "        train_dataset = train_dataset,\n",
    "        data_collator = DataCollatorForLanguageModeling(tokenizer, mlm = False)\n",
    "    )\n",
    "\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 01:24, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:40, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5, training_loss=4.086028289794922, metrics={'train_runtime': 50.9607, 'train_samples_per_second': 2.453, 'train_steps_per_second': 0.098, 'total_flos': 28795358208000.0, 'train_loss': 4.086028289794922, 'epoch': 5.0})"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## time to finetune the models\n",
    "trainer_prompt = create_trainer(peft_model_prompt, training_args_prompt, train_sample_prompt)\n",
    "trainer_prompt.train()\n",
    "\n",
    "trainer_sentences = create_trainer(peft_model_sentences, training_args_sentences, train_sample_sentences)\n",
    "trainer_sentences.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save the models\n",
    "trainer_prompt.model.save_pretrained(output_dir_prompt)\n",
    "trainer_sentences.model.save_pretrained(output_dir_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "\n",
    "loaded_model_prompt = PeftModel.from_pretrained(foundational_model,\n",
    "                                         output_dir_prompt,\n",
    "                                         #device_map='auto',\n",
    "                                         is_trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I want you to act as a motivational coach. I want you to help me make my life better']\n"
     ]
    }
   ],
   "source": [
    "## inference\n",
    "loaded_model_prompt_outputs = get_outputs(loaded_model_prompt, input_prompt)\n",
    "print(tokenizer.batch_decode(loaded_model_prompt_outputs, skip_special_tokens = True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model_sentences = PeftModel.from_pretrained(foundational_model,\n",
    "                                         output_dir_sentences,\n",
    "                                         #device_map='auto',\n",
    "                                         is_trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['There are two things that matter: quality and quantity. quality matters more than quantity']\n"
     ]
    }
   ],
   "source": [
    "## inference\n",
    "loaded_model_sentences_outputs = get_outputs(loaded_model_sentences, input_sentences)\n",
    "print(tokenizer.batch_decode(loaded_model_sentences_outputs, skip_special_tokens = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
